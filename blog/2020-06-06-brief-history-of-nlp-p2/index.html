<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.e706d8cdbf6f3e8bfa1d.css">@import url(https://fonts.googleapis.com/css?family=Open+Sans:300,400|Roboto:300,400);.Header--header--28-mG{display:block}.Header--header__container--3a_BD{flex-grow:1;margin:0 auto;padding-left:30px;padding-right:30px;max-width:1320px}@media (min-width:420px){.Header--header__container--3a_BD{max-width:1350px}}@media (min-width:720px){.Header--header__container--3a_BD{padding-left:50px;padding-right:50px;max-width:1390px}}@media (min-width:1080px){.Header--header__container--3a_BD{padding-left:70px;padding-right:70px;max-width:1430px}}.Header--header__content--19TvH{display:flex;align-items:center;padding:30px 0}.Header--header__logo--2Pboo{text-decoration:none;color:#333}.Header--header__logoSvg--26FCt{display:block;height:16px;width:auto}@media (min-width:768px){.Header--header__logoSvg--26FCt{height:18px}}.Header--header__logo--2Pboo h1{display:block;font-weight:600;font-size:medium}@media (min-width:768px){.Header--header__logo--2Pboo h1{display:inline-block;font-size:large}}.Header--header__logo--2Pboo span{color:#666;display:none}@media (min-width:768px){.Header--header__logo--2Pboo span{display:initial;padding-left:8px}}.Header--header__navigation--3RXf6{display:flex;margin-left:auto}.HeaderLink--link--XnUti{display:flex;margin-left:40px;text-decoration:none;color:#404040;transition:opacity .2s ease-in-out}.HeaderLink--link--XnUti:first-of-type{margin-left:0}.HeaderLink--link--XnUti:hover{opacity:.5}.HeaderLink--link__icon--19vgO{position:relative;margin-right:8px}.HeaderLink--link__icon--19vgO path{fill:#404040}@media (min-width:768px){.HeaderLink--link__icon--19vgO{top:3px}}.Container--container--3QHbe{flex-grow:1;margin:0 auto;padding-left:30px;padding-right:30px;max-width:1320px}@media (min-width:420px){.Container--container--3QHbe{max-width:1350px}}@media (min-width:720px){.Container--container--3QHbe{padding-left:50px;padding-right:50px;max-width:1390px}}@media (min-width:1080px){.Container--container--3QHbe{padding-left:70px;padding-right:70px;max-width:1430px}}.Footer--footer--3N4oY{position:absolute;right:0;bottom:0;left:0}.Footer--footer__content--3FUJz{display:flex;justify-content:space-between;padding:40px 0;border-bottom:10px solid #8effbf}.Footer--footer__list--3m4JX{display:flex}.Footer--footer__item--31NlX{margin-left:30px;transition:opacity .2s ease-in-out}.Footer--footer__item--31NlX:hover{opacity:.5}:root{--grid-column-count:12;--grid-baseline:16px;--grid-baseline-calc:unitless($grid-baseline)}.GridOverlay--grid--Y4CP4{position:absolute;top:0;left:0;right:0;bottom:0;z-index:10000;overflow:hidden;pointer-events:none;transform-origin:50% 0}.GridOverlay--grid__container--3ESK_{flex-grow:1;margin:0 auto;padding-left:30px;padding-right:30px;max-width:1320px;height:100%;opacity:0;transition:opacity .2s}@media (min-width:420px){.GridOverlay--grid__container--3ESK_{max-width:1350px}}@media (min-width:720px){.GridOverlay--grid__container--3ESK_{padding-left:50px;padding-right:50px;max-width:1390px}}@media (min-width:1080px){.GridOverlay--grid__container--3ESK_{padding-left:70px;padding-right:70px;max-width:1430px}}.GridOverlay--grid--Y4CP4.GridOverlay--isVerticalVisible--3gWfJ .GridOverlay--grid__container--3ESK_{opacity:1}.GridOverlay--gridIsHorizontalIsVisible--phM4F{background:linear-gradient(180deg,transparent calc(100% - 1/var(--grid-baseline-calc)*100%),rgba(0,0,0,.05) calc(100% - 1/var(--grid-baseline-calc)*100%)),linear-gradient(180deg,transparent calc(100% - 1/var(--grid-baseline-calc)*100%),hsla(0,0%,100%,.15) calc(100% - 1/var(--grid-baseline-calc)*100%));background-size:var(--grid-baseline) var(--grid-baseline)}.GridOverlay--grid__row--3VSkB{display:flex;flex-wrap:wrap;align-items:stretch;justify-content:flex-start;margin-left:-15px;margin-right:-15px;flex-direction:row;height:100%}.GridOverlay--grid__column--35GfS{flex:none;align-self:stretch;padding-left:15px;padding-right:15px;width:calc(100%/var(--grid-column-count, 12));position:relative;height:100%}.GridOverlay--grid__visualize--1dqGC{position:relative;width:100%;height:100%}.GridOverlay--grid__visualize--1dqGC:after,.GridOverlay--grid__visualize--1dqGC:before{content:"";display:block;width:100%;height:100%;background-color:hsla(0,0%,100%,.1)}.GridOverlay--grid__visualize--1dqGC:after{position:absolute;top:0;left:0;background-color:rgba(0,0,0,.05)}.GridOverlay--grid__button--3iH5z{position:fixed;right:75px;top:0;z-index:10000;padding:0 15px;height:26px;border:1px solid rgba(0,0,0,.1);border-top:0 solid rgba(0,0,0,.1);border-radius:0 0 2px 2px;cursor:pointer;pointer-events:all;font-size:12px;text-transform:uppercase;color:#999;background-color:#fff;opacity:1;transition:opacity .25s,transform .1s}.GridOverlay--grid__button--3iH5z:hover{color:#000}.GridOverlay--grid__button--3iH5z:hover g{fill:#000}.GridOverlay--grid__button--3iH5z:first-of-type{right:131px}.GridOverlay--grid__button__svg--3azhJ{margin-top:4px}.GridOverlay--grid__button__svg--3azhJ g{fill:#8d8d8d}.GridOverlay--grid__button--3iH5z.GridOverlay--horizontal--2KwNT:hover g,.GridOverlay--grid__button--3iH5z.GridOverlay--horizontal--2KwNT g,.GridOverlay--grid__button--3iH5z.GridOverlay--vertical--G5_0K:hover g,.GridOverlay--grid__button--3iH5z.GridOverlay--vertical--G5_0K g{fill:#328bf3}[data-columns="1"] .GridOverlay--grid__column--35GfS{min-width:100%}[data-columns="2"] .GridOverlay--grid__column--35GfS{min-width:50%}[data-columns="3"] .GridOverlay--grid__column--35GfS{min-width:33.33333%}[data-columns="4"] .GridOverlay--grid__column--35GfS{min-width:25%}[data-columns="5"] .GridOverlay--grid__column--35GfS{min-width:20%}[data-columns="6"] .GridOverlay--grid__column--35GfS{min-width:16.66667%}[data-columns="7"] .GridOverlay--grid__column--35GfS{min-width:14.28571%}[data-columns="8"] .GridOverlay--grid__column--35GfS{min-width:12.5%}[data-columns="9"] .GridOverlay--grid__column--35GfS{min-width:11.11111%}[data-columns="10"] .GridOverlay--grid__column--35GfS{min-width:10%}[data-columns="11"] .GridOverlay--grid__column--35GfS{min-width:9.09091%}[data-columns="12"] .GridOverlay--grid__column--35GfS{min-width:8.33333%}a,abbr,acronym,address,applet,article,aside,audio,b,big,blockquote,body,canvas,caption,center,cite,code,dd,del,details,dfn,div,dl,dt,em,embed,fieldset,figcaption,figure,footer,form,h1,h2,h3,h4,h5,h6,header,hgroup,hr,html,i,iframe,img,ins,kbd,label,legend,li,mark,menu,nav,object,ol,output,p,pre,q,ruby,s,samp,section,small,span,strike,strong,sub,summary,sup,table,tbody,td,tfoot,th,thead,time,tr,tt,u,ul,var,video{margin:0;padding:0;font-family:inherit;font-style:inherit;font-size:inherit;font-weight:inherit;border:0;border-radius:0}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:after,blockquote:before,q:after,q:before{content:"";content:none}table{border-collapse:collapse;border-spacing:0}button,input,select,textarea{font-family:inherit;font-style:inherit;font-size:inherit;font-weight:inherit;border:0;-webkit-appearance:none;-moz-appearance:none;appearance:none}button:focus:not(:focus-visible),input:focus:not(:focus-visible),select:focus:not(:focus-visible),textarea:focus:not(:focus-visible){outline:none}.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:flex;flex:0 1 auto;flex-direction:row;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{flex-direction:row-reverse}.col.reverse{flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12{box-sizing:border-box;flex:0 0 auto;padding-right:.5rem;padding-left:.5rem}.col-xs{flex-grow:1;flex-basis:0;max-width:100%}.col-xs-1{flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{flex-basis:25%;max-width:25%}.col-xs-4{flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{flex-basis:50%;max-width:50%}.col-xs-7{flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{flex-basis:75%;max-width:75%}.col-xs-10{flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{justify-content:flex-start;text-align:start}.center-xs{justify-content:center;text-align:center}.end-xs{justify-content:flex-end;text-align:end}.top-xs{align-items:flex-start}.middle-xs{align-items:center}.bottom-xs{align-items:flex-end}.around-xs{justify-content:space-around}.between-xs{justify-content:space-between}.first-xs{order:-1}.last-xs{order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12{box-sizing:border-box;flex:0 0 auto;padding-right:.5rem;padding-left:.5rem}.col-sm{flex-grow:1;flex-basis:0;max-width:100%}.col-sm-1{flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{flex-basis:25%;max-width:25%}.col-sm-4{flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{flex-basis:50%;max-width:50%}.col-sm-7{flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{flex-basis:75%;max-width:75%}.col-sm-10{flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{justify-content:flex-start;text-align:start}.center-sm{justify-content:center;text-align:center}.end-sm{justify-content:flex-end;text-align:end}.top-sm{align-items:flex-start}.middle-sm{align-items:center}.bottom-sm{align-items:flex-end}.around-sm{justify-content:space-around}.between-sm{justify-content:space-between}.first-sm{order:-1}.last-sm{order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-10,.col-md-11,.col-md-12,.col-md-offset-0,.col-md-offset-1,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12{box-sizing:border-box;flex:0 0 auto;padding-right:.5rem;padding-left:.5rem}.col-md{flex-grow:1;flex-basis:0;max-width:100%}.col-md-1{flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{flex-basis:25%;max-width:25%}.col-md-4{flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{flex-basis:50%;max-width:50%}.col-md-7{flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{flex-basis:75%;max-width:75%}.col-md-10{flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{justify-content:flex-start;text-align:start}.center-md{justify-content:center;text-align:center}.end-md{justify-content:flex-end;text-align:end}.top-md{align-items:flex-start}.middle-md{align-items:center}.bottom-md{align-items:flex-end}.around-md{justify-content:space-around}.between-md{justify-content:space-between}.first-md{order:-1}.last-md{order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12{box-sizing:border-box;flex:0 0 auto;padding-right:.5rem;padding-left:.5rem}.col-lg{flex-grow:1;flex-basis:0;max-width:100%}.col-lg-1{flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{flex-basis:25%;max-width:25%}.col-lg-4{flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{flex-basis:50%;max-width:50%}.col-lg-7{flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{flex-basis:75%;max-width:75%}.col-lg-10{flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{justify-content:flex-start;text-align:start}.center-lg{justify-content:center;text-align:center}.end-lg{justify-content:flex-end;text-align:end}.top-lg{align-items:flex-start}.middle-lg{align-items:center}.bottom-lg{align-items:flex-end}.around-lg{justify-content:space-around}.between-lg{justify-content:space-between}.first-lg{order:-1}.last-lg{order:1}}:root{--scale-element:1;--scale-font:1}@media (max-height:920px){:root{--scale-element:0.975;--scale-font:0.975}}@media (max-height:800px){:root{--scale-element:0.95;--scale-font:0.95}}@media (max-height:690px){:root{--scale-element:0.925;--scale-font:0.925}}body,html{min-height:100vh;background-color:#fff}html{-webkit-overflow-scrolling:touch;overflow-x:hidden;overflow-y:scroll;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box}*,:after,:before{box-sizing:inherit}body{font-size:13px;font-size:calc(13px*var(--scale-font));position:relative;margin:0;font-family:Roboto,sans-serif;line-height:1.5;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%;text-size-adjust:100%;color:#333}@media (min-width:420px){body{font-size:13px;font-size:calc((.297vw + 11.75248px)*var(--scale-font))}}@media (min-width:1430px){body{font-size:16px;font-size:calc(16px*var(--scale-font))}}img{display:block;max-width:100%;height:auto}input::-webkit-input-placeholder,select::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#ddd}input::-moz-placeholder,select::-moz-placeholder,textarea::-moz-placeholder{opacity:1;color:#ddd}input:-ms-input-placeholder,select:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#ddd}a{color:#1a1a1a;font-weight:400;text-decoration:none;transition:opacity .2s ease-in-out}a:hover{opacity:.5}.AppLayout--layout--2MnEp{display:block;min-height:100vh}code[class*=language-],pre[class*=language-]{color:#000;background:none;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{position:relative;margin:.5em 0;overflow:visible;padding:0}pre[class*=language-]>code{position:relative;border-left:10px solid #358ccb;box-shadow:-1px 0 0 0 #358ccb,0 0 0 1px #dfdfdf;background-color:#fdfdfd;background-image:linear-gradient(transparent 50%,rgba(69,142,209,.04) 0);background-size:3em 3em;background-origin:content-box;background-attachment:local}code[class*=language]{max-height:inherit;height:inherit;padding:0 1em;display:block;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background-color:#fdfdfd;box-sizing:border-box;margin-bottom:1em}:not(pre)>code[class*=language-]{position:relative;padding:.2em;border-radius:.3em;color:#c92c2c;border:1px solid rgba(0,0,0,.1);display:inline;white-space:normal}pre[class*=language-]:after,pre[class*=language-]:before{content:"";z-index:-2;display:block;position:absolute;bottom:.75em;left:.18em;width:40%;height:20%;max-height:13em;box-shadow:0 13px 8px #979797;transform:rotate(-2deg)}:not(pre)>code[class*=language-]:after,pre[class*=language-]:after{right:.75em;left:auto;transform:rotate(2deg)}.token.block-comment,.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#7d8b99}.token.punctuation{color:#5f6364}.token.boolean,.token.constant,.token.deleted,.token.function-name,.token.number,.token.property,.token.symbol,.token.tag{color:#c92c2c}.token.attr-name,.token.builtin,.token.char,.token.function,.token.inserted,.token.selector,.token.string{color:#2f9c0a}.token.entity,.token.operator,.token.url,.token.variable{color:#a67f59;background:hsla(0,0%,100%,.5)}.token.atrule,.token.attr-value,.token.class-name,.token.keyword{color:#1990b8}.token.important,.token.regex{color:#e90}.language-css .token.string,.style .token.string{color:#a67f59;background:hsla(0,0%,100%,.5)}.token.important{font-weight:400}.token.bold{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.token.namespace{opacity:.7}@media screen and (max-width:767px){pre[class*=language-]:after,pre[class*=language-]:before{bottom:14px;box-shadow:none}}.token.cr:before,.token.lf:before,.token.tab:not(:empty):before{color:#e0d7d1}pre[class*=language-].line-numbers.line-numbers{padding-left:0}pre[class*=language-].line-numbers.line-numbers code{padding-left:3.8em}pre[class*=language-].line-numbers.line-numbers .line-numbers-rows{left:0}pre[class*=language-][data-line]{padding-top:0;padding-bottom:0;padding-left:0}pre[data-line] code{position:relative;padding-left:4em}pre .line-highlight{margin-top:0}.AboutColumn--about_col--26z37{padding:6px 0;transition:opacity .2s ease-in-out;opacity:.7}.AboutColumn--about_col--26z37 ul{display:none}.AboutColumn--about_col--26z37:hover{opacity:1}.AboutColumn--about_col__avatar--2ngtn img{width:48px;height:48px;border-radius:50%;padding:5px;border:1px solid #f2f3f3}.AboutColumn--about_col__heading--3lDv_{font-size:22px;font-size:calc(22px*var(--scale-font));margin-bottom:5px;font-family:Open Sans,sans-serif;font-weight:300}@media (min-width:420px){.AboutColumn--about_col__heading--3lDv_{font-size:22px;font-size:calc((.396vw + 20.33663px)*var(--scale-font))}}@media (min-width:1430px){.AboutColumn--about_col__heading--3lDv_{font-size:26px;font-size:calc(26px*var(--scale-font))}}.AboutColumn--about_col__desc_container--3zM2q{padding:0;margin-left:12px}.AboutColumn--about_col__description--2PPLk{margin-bottom:5px;line-height:1.625;font-style:italic}.AboutColumn--about_col__details--2IU9H{line-height:2;-webkit-user-select:none;-ms-user-select:none;user-select:none}.AboutColumn--about_col__details__icon--GlkQJ{display:inline-block;width:28px}.AboutColumn--about_col__details__text--15yIn{padding:8px 0;font-weight:400}@media only screen and (min-width:48em){.AboutColumn--about_col--26z37{padding:60px 12px;max-width:100%}.AboutColumn--about_col--26z37 ul{display:block}.AboutColumn--about_col__avatar--2ngtn img{width:110px;height:110px}.AboutColumn--about_col__desc_container--3zM2q{margin-left:0}.AboutColumn--about_col__heading--3lDv_{margin-bottom:12px}.AboutColumn--about_col__description--2PPLk{margin-bottom:18px}}.PostsLayout--layout--Gqf2W{min-height:100vh}.PostsLayout--side_bar--13dgS{margin-left:auto;margin-right:auto}@media only screen and (min-width:48em){.PostsLayout--side_bar--13dgS{margin-left:0;margin-right:0}}.PostsLayout--posts_content--3-D5A{text-align:justify;margin-bottom:128px;margin-left:12px;margin-right:24px;width:100%}@media only screen and (min-width:48em){.PostsLayout--posts_content--3-D5A{margin-left:0;margin-right:0}}.PostsLayout--posts_content--3-D5A a{color:#497e60}.PostsLayout--posts_content--3-D5A ol,.PostsLayout--posts_content--3-D5A p,.PostsLayout--posts_content--3-D5A ul{margin:0 0 1.3em}.PostsLayout--posts_content--3-D5A h1{font-size:larger}.PostsLayout--posts_content--3-D5A h1,.PostsLayout--posts_content--3-D5A h2,.PostsLayout--posts_content--3-D5A h3,.PostsLayout--posts_content--3-D5A h4,.PostsLayout--posts_content--3-D5A h5,.PostsLayout--posts_content--3-D5A h6{font-weight:400;line-height:3em}.PostsLayout--posts_content--3-D5A ol{list-style:decimal inside}.PostsLayout--posts_content--3-D5A ul{list-style:inside}.PostsLayout--posts_content--3-D5A em{font-style:italic}.PostsLayout--posts_content--3-D5A strong{font-weight:400}.PostsLayout--posts_content--3-D5A sup{font-size:small}.PostsLayout--posts_content--3-D5A hr{border-bottom:1px solid #333;margin-bottom:8px}.PostsLayout--posts_content--3-D5A table{width:100%;border-collapse:collapse;border-spacing:.5rem;margin:18px 0}.PostsLayout--posts_content--3-D5A td,.PostsLayout--posts_content--3-D5A th{border:thin solid #999;padding:.5em}.PostsLayout--posts_content--3-D5A th{color:#479b6b;font-weight:400}.PostsLayout--posts_content--3-D5A blockquote{margin:2em 1em;border-left:.25em solid #666;padding-left:1em;font-style:italic}.PostsLayout--posts_content--3-D5A figcaption{margin:8px 0;font-size:.8em;text-align:center}div.gist-data{max-height:500px;line-height:normal}div.gist table{border-spacing:0}div.gist th,td{border:0!important;padding:.5em}div.gatsby-highlight{font-size:13px}.PageHeader--page_header--2rnMf{padding:20px 0;border-bottom:1px solid #e5e5e5}.PageHeader--page_header__text--1lzLq{font-size:26px;font-size:calc(26px*var(--scale-font));font-family:Open Sans,sans-serif;font-weight:300}@media (min-width:420px){.PageHeader--page_header__text--1lzLq{font-size:26px;font-size:calc((.594vw + 23.50495px)*var(--scale-font))}}@media (min-width:1430px){.PageHeader--page_header__text--1lzLq{font-size:32px;font-size:calc(32px*var(--scale-font))}}.BlogPost--post_meta--10FMO{margin-top:36px}.BlogPost--post_meta--10FMO span{font-weight:300}.BlogPost--post_meta--10FMO span svg{width:.8em;margin-right:12px}.BlogPost--post_content--1ZOta{margin-top:20px;margin-bottom:20px;font-size:16px;font-size:calc(16px*var(--scale-font));font-weight:300;line-height:1.625;padding-bottom:20px;border-bottom:1px solid #e5e5e5}@media (min-width:420px){.BlogPost--post_content--1ZOta{font-size:16px;font-size:calc((.198vw + 15.16832px)*var(--scale-font))}}@media (min-width:1430px){.BlogPost--post_content--1ZOta{font-size:18px;font-size:calc(18px*var(--scale-font))}}.Segment--segment--25ls6{flex-grow:1;padding-top:90px;padding-bottom:90px}@supports (--css:variables){.Segment--segment--25ls6{padding-top:calc(90px*var(--scale-element));padding-bottom:calc(90px*var(--scale-element))}}@media (min-width:720px){.Segment--segment--25ls6{padding-top:13.98601%;padding-bottom:13.98601%}@supports (--css:variables){.Segment--segment--25ls6{padding-top:calc(13.98601%*var(--scale-element));padding-bottom:calc(13.98601%*var(--scale-element))}}}@media (min-width:1430px){.Segment--segment--25ls6{padding-top:200px;padding-bottom:200px}@supports (--css:variables){.Segment--segment--25ls6{padding-top:calc(200px*var(--scale-element));padding-bottom:calc(200px*var(--scale-element))}}}.Row--row--1qryC{display:flex;flex-wrap:wrap;align-items:stretch;justify-content:flex-start;margin-left:-15px;margin-right:-15px;flex-direction:row}.Intro--intro--1ikoV{padding:60px 0;border-bottom:1px solid #e5e5e5}@media (min-width:768px){.Intro--intro--1ikoV{padding:120px 0}}.Intro--intro__col--1DEvw{flex:none;align-self:stretch;padding-left:15px;padding-right:15px;width:100%}@media (min-width:768px){.Intro--intro__col--1DEvw{flex:none;align-self:stretch;padding-left:15px;padding-right:15px;width:58.33333%}}.Intro--intro__text--3TVV0{font-size:26px;font-size:calc(26px*var(--scale-font));font-family:Open Sans,sans-serif;font-weight:300}@media (min-width:420px){.Intro--intro__text--3TVV0{font-size:26px;font-size:calc((.594vw + 23.50495px)*var(--scale-font))}}@media (min-width:1430px){.Intro--intro__text--3TVV0{font-size:32px;font-size:calc(32px*var(--scale-font))}}.Highlight--highlight--3UCQk{position:relative}.Highlight--highlight__text--Vp1sx{position:relative;z-index:1}.Highlight--isFirst--31-VV .Highlight--highlight__text--Vp1sx{padding-right:10px}.Highlight--highlight__color--1tDIQ{position:absolute;bottom:8px;left:0;z-index:0;width:100%;height:16px;background-color:rgba(142,255,191,.3)}.BlockText--block--dl83v{padding:60px 0}@media (min-width:768px){.BlockText--block--dl83v{padding:80px 0}}.BlockText--block__col--1qMGo{flex:none;align-self:stretch;padding-left:15px;padding-right:15px;width:100%}@media (min-width:768px){.BlockText--block__col--1qMGo{flex:none;align-self:stretch;padding-left:15px;padding-right:15px;width:41.66667%}}@media (min-width:768px){.BlockText--block__col--1qMGo.BlockText--full_width--2ucFH{flex:none;align-self:stretch;padding-left:15px;padding-right:15px;width:100%}}.BlockText--block__heading--jWMrW{font-size:16px;font-size:calc(16px*var(--scale-font));margin-bottom:10px;font-family:Open Sans,sans-serif}@media (min-width:420px){.BlockText--block__heading--jWMrW{font-size:16px;font-size:calc((.198vw + 15.16832px)*var(--scale-font))}}@media (min-width:1430px){.BlockText--block__heading--jWMrW{font-size:18px;font-size:calc(18px*var(--scale-font))}}.BlockText--block__heading--jWMrW a{display:inline-block;margin-left:12px!important}.BlockText--block__description--Sz8So{font-size:16px;font-size:calc(16px*var(--scale-font));font-weight:300;line-height:1.625}@media (min-width:420px){.BlockText--block__description--Sz8So{font-size:16px;font-size:calc((.198vw + 15.16832px)*var(--scale-font))}}@media (min-width:1430px){.BlockText--block__description--Sz8So{font-size:18px;font-size:calc(18px*var(--scale-font))}}.BlockText--block__description--Sz8So a{text-decoration:none;font-weight:400;color:#000;transition:opacity .2s ease-in-out}.BlockText--block__description--Sz8So a:hover{opacity:.5}.BlockText--block__description--Sz8So p{margin-bottom:1.3em}.PostTag--post_tag--pzPW_{padding:0 5px;margin:1px 4px 1px 0;border:1px solid #999;border-radius:2px;color:#333;opacity:.8}.PostBrief--post_brief--1CGN-{border:1px solid #e6e6e6;box-shadow:0 10px 10px 0 rgba(50,128,122,.2);border-radius:5px;padding:24px;margin:12px 12px 24px;opacity:.8;transition:opacity .2s ease-in-out}.PostBrief--post_brief--1CGN-:hover{opacity:1}.PostBrief--post_brief--1CGN-:after{content:"";clear:both;display:table}.PostBrief--post_brief--1CGN- header{font-family:Open Sans,sans-serif;font-weight:300}.PostBrief--post_brief--1CGN- header a{font-weight:400;line-height:1.5rem}.PostBrief--post_brief--1CGN- header.PostBrief--small--U54Cr a{display:block;overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.PostBrief--post_brief__meta--Zr7qE{font-size:.8em;display:inline-block}.PostBrief--post_brief__meta--Zr7qE svg{width:.8em}.PostBrief--post_brief__meta--Zr7qE.PostBrief--small--U54Cr{margin-top:5px;display:block}.PostBrief--post_brief__content--1ohV5{margin:12px 0;font-family:Roboto,sans-serif;text-align:justify}.PostBrief--post_brief__content--1ohV5.PostBrief--small--U54Cr{line-height:24px;max-height:120px;overflow:hidden;text-overflow:ellipsis}.PostBrief--post_brief__back_top--2QS3Q{float:right;text-transform:uppercase;font-size:.8em}.PostBrief--post_brief__back_top--2QS3Q.PostBrief--small--U54Cr{display:none}.PublishedYear--published_year--3MtIk{font-size:18px;font-size:calc(18px*var(--scale-font));margin:24px 12px 18px;padding:0 24px;font-family:Open Sans,sans-serif;font-weight:300}@media (min-width:420px){.PublishedYear--published_year--3MtIk{font-size:18px;font-size:calc((.594vw + 15.50495px)*var(--scale-font))}}@media (min-width:1430px){.PublishedYear--published_year--3MtIk{font-size:24px;font-size:calc(24px*var(--scale-font))}}</style><meta name="generator" content="Gatsby 2.21.10"/><link rel="preconnect dns-prefetch" href="https://www.google-analytics.com"/><title data-react-helmet="true">A history of progress on text representation in NLP (Part 2 - Sentence-level representation) - Ngoc Nguyen&#x27;s Personal Blog</title><link data-react-helmet="true" rel="icon" type="image/x-icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAA8CAMAAAANIilAAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAKVQTFRFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA////VEBv8wAAADV0Uk5TAAIGCAMeR2qRrbyPaUic1fdCPafu7KYZjeorr/2uJjjNyAX+6e2EH9OQvQGbg0PrOo7HCTmYrbJMAAAAAWJLR0Q2R7+I0QAAAAlwSFlzAAAASAAAAEgARslrPgAAASxJREFUSMftlmtTgzAQRUlSbFMIYKoU2tLWPihStVrd///XfIwzjiObTQkzfuF8P5PsEO5dz+vp+S8YF4KzFuLAvxqO5Hgsg1D5g4tUoaI4gW+SOLoW1irXkxv4xW2quZ07zXL4Q55NbdzZfAENLIol7a7WgHC3Is9FXYD1jJi3AAOFce5NtjXJ22xjkPUOjOw07ooUCFL8tag9Je/Ro1lEuQAlJh9iWq4O2K0TWk4UIoe0CxAiI9/byKPmdODSRpbN/6aobeRadC87XfsY2MjBsftP5fZInJ4ne6DlRw/j6US5+TMqO4WBUwyRAfhiCkCn6PW85Rl3z2ThuNQNXnRzi6Jzq9imcj9NbMv9g1ddVj9rRVW+2a8Vn7CvhaauZTBUfpuNqPUq1dPTDe+aneJZFBlcXwAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAxNi0xMS0xOFQxNTozMjo0NyswMDowMBJiPnAAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMTYtMTEtMThUMTU6MzI6NDcrMDA6MDBjP4bMAAAARnRFWHRzb2Z0d2FyZQBJbWFnZU1hZ2ljayA2LjcuOC05IDIwMTQtMDUtMTIgUTE2IGh0dHA6Ly93d3cuaW1hZ2VtYWdpY2sub3Jn3IbtAAAAABh0RVh0VGh1bWI6OkRvY3VtZW50OjpQYWdlcwAxp/+7LwAAABh0RVh0VGh1bWI6OkltYWdlOjpoZWlnaHQAMTkyDwByhQAAABd0RVh0VGh1bWI6OkltYWdlOjpXaWR0aAAxOTLTrCEIAAAAGXRFWHRUaHVtYjo6TWltZXR5cGUAaW1hZ2UvcG5nP7JWTgAAABd0RVh0VGh1bWI6Ok1UaW1lADE0Nzk0ODMxNjfDDOUEAAAAD3RFWHRUaHVtYjo6U2l6ZQAwQkKUoj7sAAAAVnRFWHRUaHVtYjo6VVJJAGZpbGU6Ly8vbW50bG9nL2Zhdmljb25zLzIwMTYtMTEtMTgvOTJiZjNlMDg0MGFkZWJjNjRlMjZhMzgzODFmM2RkMmMuaWNvLnBuZ7VafDgAAAAASUVORK5CYII="/><meta data-react-helmet="true" name="description" content="Ngoc Nguyen is a Singapore-based Software Developer. Currently employed @ 2359Media"/><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/><meta data-react-helmet="true" name="apple-mobile-web-app-status-bar-style" content="black"/><meta data-react-helmet="true" name="msapplication-navbutton-color" content="#000"/><meta data-react-helmet="true" name="msapplication-TileColor" content="#000"/><meta data-react-helmet="true" name="theme-color" content="#000"/><meta data-react-helmet="true" name="google-site-verification" content="UlnCqEaT-_IXvcf5Y5levG2YHwz2v0cksM9XxTDMh7E"/><meta data-react-helmet="true" property="og:title" content="Ngoc Nguyen&#x27;s Personal Blog"/><meta data-react-helmet="true" property="og:image" content="/static/share-dee110c649a4613527a76746fe38ad6f.png"/><meta data-react-helmet="true" property="og:image:width" content="880px"/><meta data-react-helmet="true" property="og:image:height" content="440px"/><meta data-react-helmet="true" property="og:image:alt" content="Ngoc Nguyen is a Singapore-based Software Developer. Currently employed @ 2359Media"/><meta data-react-helmet="true" name="twitter:title" content="Ngoc Nguyen&#x27;s Personal Blog"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:image" content="/static/share-dee110c649a4613527a76746fe38ad6f.png"/><meta data-react-helmet="true" name="twitter:site" content="@luungoc2005"/><meta data-react-helmet="true" name="twitter:creator" content="@luungoc2005"/><meta data-react-helmet="true" name="twitter:description" content="Ngoc Nguyen is a Singapore-based Software Developer. Currently employed @ 2359Media"/><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-b3b573358bfc66d89e1e95dbf8319c09.css"/><link rel="icon" href="/favicon-32x32.png?v=e8b5b511a71c71f442909c7048bf07c6"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="theme-color" content="#663399"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=e8b5b511a71c71f442909c7048bf07c6"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=e8b5b511a71c71f442909c7048bf07c6"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=e8b5b511a71c71f442909c7048bf07c6"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=e8b5b511a71c71f442909c7048bf07c6"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=e8b5b511a71c71f442909c7048bf07c6"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=e8b5b511a71c71f442909c7048bf07c6"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=e8b5b511a71c71f442909c7048bf07c6"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=e8b5b511a71c71f442909c7048bf07c6"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link as="script" rel="preload" href="/webpack-runtime-4f6fc807c3862521eb29.js"/><link as="script" rel="preload" href="/framework-5dd3c501fd049989ea3a.js"/><link as="script" rel="preload" href="/app-d996fbcb14d4968f7635.js"/><link as="script" rel="preload" href="/styles-8636a280cbc61d53ad10.js"/><link as="script" rel="preload" href="/component---src-components-blog-post-blog-post-tsx-47ff1ab6a59cdc040003.js"/><link as="fetch" rel="preload" href="/page-data/blog/2020-06-06-brief-history-of-nlp-p2/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="AppLayout--layout--2MnEp"><header class="Header--header--28-mG" id="page-title"><div class="Header--header__container--3a_BD"><div class="Header--header__content--19TvH"><a class="Header--header__logo--2Pboo" href="/"><h1>Ngoc Nguyen</h1><span>~ programming and stuffs</span></a><div class="Header--header__navigation--3RXf6"><a class="HeaderLink--link--XnUti" href="/blog">blog</a><a class="HeaderLink--link--XnUti" href="/about">about</a><a class="HeaderLink--link--XnUti" target="_blank" rel="noopener noreferrer" href="https://github.com/luungoc2005"><svg height="17" viewBox="0 0 18 17" width="18" class="HeaderLink--link__icon--19vgO"><title>Github</title><path d="m195.711029 1c-4.810968 0-8.711029 3.90006063-8.711029 8.71102924 0 3.85027496 2.500065 7.11691086 5.958344 8.27547776.435551.0696883.574928-.2003537.574928-.4355514 0-.2003537 0-.7491486 0-1.472164-2.412955.5226618-2.926906-1.1672779-2.926906-1.1672779-.400707-1.0104794-.966924-1.2805213-.966924-1.2805213-.792704-.5400838.060977-.5226618.060977-.5226618.871103.0609772 1.332788.8972361 1.332788.8972361.757859 1.3240764 2.03838.9320801 2.534909.7230154.078399-.5662169.304886-.9495022.548795-1.1672779-1.933849-.2177758-3.963518-.9669243-3.963518-4.28582642 0-.96692425.331019-1.74220585.897236-2.36068893-.087111-.21777573-.391997-1.12372277.08711-2.29971172 0 0 .731726-.23519779 2.395533.88852499.688171-.19164265 1.43732-.28746397 2.177757-.28746397.740438 0 1.489586.09582132 2.177758.28746397 1.663806-1.12372278 2.395533-.88852499 2.395533-.88852499.479106 1.17598895.17422 2.08193599.08711 2.29971172.566217.61848308.897236 1.39376468.897236 2.36068893 0 3.32761312-2.038381 4.05933962-3.98094 4.27711532.313597.2700419.601061.8014147.601061 1.6115404v2.3868221c0 .2351977.139376.5139507.583639.4355514 3.458278-1.1672779 5.949632-4.4252028 5.949632-8.27547776 0-2.3103086-.917766-4.52599297-2.551401-6.15962785-1.633635-1.63363487-3.849319-2.55140139-6.159628-2.55140139z" fill="#9ea0a6" transform="translate(-187 -1)"></path></svg>github</a></div></div></div></header><div class="PostsLayout--layout--Gqf2W"><div class="container-fluid row" style="margin-left:auto;margin-right:auto"><aside class="col-xs-12 col-sm-3 PostsLayout--side_bar--13dgS"><div class="row AboutColumn--about_col--26z37"><div class="col-xs-2 col-sm-12 AboutColumn--about_col__avatar--2ngtn"><img alt="Avatar" src="/static/avatar-b02e09c908376b498e9c9961bc2de3c8.png"/></div><div class="col-xs-8 col-sm-12 AboutColumn--about_col__desc_container--3zM2q"><div class="AboutColumn--about_col__heading--3lDv_">Ngoc Nguyen</div><div class="AboutColumn--about_col__description--2PPLk">Software Developer, AI Enthusiast, Coffee Addict, plays Piano</div></div><div class="AboutColumn--about_col__details--2IU9H"><ul><li><span class="AboutColumn--about_col__details__icon--GlkQJ"><svg class="svg-inline--fa fa-map-marker-alt fa-w-12 fa-fw" width="18" height="18" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="map-marker-alt" role="img" viewBox="0 0 384 512" data-fa-i2svg=""><title>Location</title><path fill="currentColor" d="M172.268 501.67C26.97 291.031 0 269.413 0 192 0 85.961 85.961 0 192 0s192 85.961 192 192c0 77.413-26.97 99.031-172.268 309.67-9.535 13.774-29.93 13.773-39.464 0zM192 272c44.183 0 80-35.817 80-80s-35.817-80-80-80-80 35.817-80 80 35.817 80 80 80z"></path></svg></span><span class="AboutColumn--about_col__details__text--15yIn">Singapore</span></li><li><a alt="Twitter" href="https://twitter.com/luungoc2005" target="_blank" rel="noopener noreferrer"><span class="AboutColumn--about_col__details__icon--GlkQJ"><svg width="20px" height="15px" viewBox="0 0 20 15" version="1.1"><title>Twitter</title><defs></defs><g id="Good-One" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Footer_06" transform="translate(-1091.000000, -3948.000000)" fill="#9EA0A6"><g id="Group-7" transform="translate(0.000000, 3204.000000)"><g id="Group-6" transform="translate(75.000000, 733.000000)"><g id="dribbble" transform="translate(976.000000, 9.000000)"><path d="M53.2813915,2 C51.0959361,2 49.3247358,3.69382235 49.3247358,5.78774534 C49.3247358,6.08310267 49.3596502,6.37374182 49.4275918,6.64928284 C46.1380851,6.48980876 43.2222572,4.98471314 41.2708228,2.68885254 C40.9301711,3.25031454 40.7357826,3.90142174 40.7357826,4.59593608 C40.7357826,5.91041772 41.4331278,7.07014343 42.4956593,7.74672874 C41.8464394,7.72974333 41.236852,7.55800201 40.7027554,7.27396829 C40.7027554,7.29001007 40.7027554,7.30605184 40.7027554,7.32303724 C40.7027554,9.157461 42.066306,10.6880347 43.8771389,11.0362355 C43.5449799,11.1221062 43.1958354,11.1692879 42.8344238,11.1692879 C42.5796427,11.1692879 42.331467,11.1447534 42.0898968,11.1032335 C42.5937972,12.603611 44.0554857,13.7038878 45.7870533,13.7331404 C44.4319955,14.7447157 42.7259059,15.3552466 40.8726095,15.3552466 C40.5527177,15.3552466 40.237544,15.3344867 39.9280322,15.3014595 C41.6794162,16.3753145 43.7591847,17 45.9937091,17 C53.2719552,17 57.2522018,11.2287368 57.2522018,6.22464771 C57.2522018,6.06328636 57.2484273,5.89720684 57.2408782,5.73490186 C58.0146578,5.20080523 58.6855813,4.53648717 59.2159034,3.7768621 C58.5062909,4.07505033 57.7438349,4.27887519 56.9436336,4.37135128 C57.7598767,3.90142174 58.3873931,3.16066935 58.6827504,2.27648465 C57.9184071,2.70961248 57.0710242,3.02478611 56.1707977,3.19369653 C55.4479743,2.45954957 54.4203573,2 53.2813915,2" id="Fill-1"></path></g></g></g></g></g></svg></span><span class="AboutColumn--about_col__details__text--15yIn">Twitter</span></a></li><li><a alt="Github" href="https://github.com/luungoc2005" target="_blank" rel="noopener noreferrer"><span class="AboutColumn--about_col__details__icon--GlkQJ"><svg height="17" viewBox="0 0 18 17" width="18"><title>Github</title><path d="m195.711029 1c-4.810968 0-8.711029 3.90006063-8.711029 8.71102924 0 3.85027496 2.500065 7.11691086 5.958344 8.27547776.435551.0696883.574928-.2003537.574928-.4355514 0-.2003537 0-.7491486 0-1.472164-2.412955.5226618-2.926906-1.1672779-2.926906-1.1672779-.400707-1.0104794-.966924-1.2805213-.966924-1.2805213-.792704-.5400838.060977-.5226618.060977-.5226618.871103.0609772 1.332788.8972361 1.332788.8972361.757859 1.3240764 2.03838.9320801 2.534909.7230154.078399-.5662169.304886-.9495022.548795-1.1672779-1.933849-.2177758-3.963518-.9669243-3.963518-4.28582642 0-.96692425.331019-1.74220585.897236-2.36068893-.087111-.21777573-.391997-1.12372277.08711-2.29971172 0 0 .731726-.23519779 2.395533.88852499.688171-.19164265 1.43732-.28746397 2.177757-.28746397.740438 0 1.489586.09582132 2.177758.28746397 1.663806-1.12372278 2.395533-.88852499 2.395533-.88852499.479106 1.17598895.17422 2.08193599.08711 2.29971172.566217.61848308.897236 1.39376468.897236 2.36068893 0 3.32761312-2.038381 4.05933962-3.98094 4.27711532.313597.2700419.601061.8014147.601061 1.6115404v2.3868221c0 .2351977.139376.5139507.583639.4355514 3.458278-1.1672779 5.949632-4.4252028 5.949632-8.27547776 0-2.3103086-.917766-4.52599297-2.551401-6.15962785-1.633635-1.63363487-3.849319-2.55140139-6.159628-2.55140139z" fill="#9ea0a6" transform="translate(-187 -1)"></path></svg></span><span class="AboutColumn--about_col__details__text--15yIn">Github</span></a></li><li><a alt="Facebook" href="https://www.facebook.com/luungoc2005" target="_blank" rel="noopener noreferrer"><span class="AboutColumn--about_col__details__icon--GlkQJ"><svg width="9px" height="18px" viewBox="0 0 9 18" version="1.1"><title>Facebook</title><defs></defs><g id="Good-One" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Footer_06" transform="translate(-1051.000000, -3946.000000)" fill="#9EA0A6" fill-rule="nonzero"><g id="Group-7" transform="translate(0.000000, 3204.000000)"><g id="Group-6" transform="translate(75.000000, 733.000000)"><g id="dribbble" transform="translate(976.000000, 9.000000)"><path d="M9,0 L9,3.6 L7.2,3.6 C6.579,3.6 6.3,4.329 6.3,4.95 L6.3,7.2 L9,7.2 L9,10.8 L6.3,10.8 L6.3,18 L2.7,18 L2.7,10.8 L0,10.8 L0,7.2 L2.7,7.2 L2.7,3.6 C2.7,1.6117749 4.3117749,3.99680289e-16 6.3,0 L9,0 Z" id="Shape"></path></g></g></g></g></g></svg></span><span class="AboutColumn--about_col__details__text--15yIn">Facebook</span></a></li><li><a alt="LinkedIn" href="https://www.linkedin.com/in/luungoc2005/" target="_blank" rel="noopener noreferrer"><span class="AboutColumn--about_col__details__icon--GlkQJ"><svg width="18" height="18" viewBox="0 0 18 18"><title>
    LinkedIn
  </title><path fill="#9EA0A6" fill-rule="nonzero" d="M18 18h-4v-6.75c0-1.06-1.19-1.94-2.25-1.94S10 10.19 10 11.25V18H6V6h4v2c.66-1.07 2.36-1.76 3.5-1.76 2.5 0 4.5 2.04 4.5 4.51V18zM4 18H0V6h4v12zM2 0a2 2 0 1 1 0 4 2 2 0 0 1 0-4z"></path></svg></span><span class="AboutColumn--about_col__details__text--15yIn">LinkedIn</span></a></li></ul></div></div></aside><section class="col-xs-12 col-sm-9 PostsLayout--posts_content--3-D5A"><header><div class="PageHeader--page_header--2rnMf"><p class="PageHeader--page_header__text--1lzLq">A history of progress on text representation in NLP (Part 2 - Sentence-level representation)</p></div></header><section class="BlogPost--post_meta--10FMO"><span><svg class="svg-inline--fa fa-calendar-alt fa-w-14 fa-fw" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="calendar-alt" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M0 464c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48V192H0v272zm320-196c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12h-40c-6.6 0-12-5.4-12-12v-40zm0 128c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12h-40c-6.6 0-12-5.4-12-12v-40zM192 268c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12h-40c-6.6 0-12-5.4-12-12v-40zm0 128c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12h-40c-6.6 0-12-5.4-12-12v-40zM64 268c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12H76c-6.6 0-12-5.4-12-12v-40zm0 128c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12H76c-6.6 0-12-5.4-12-12v-40zM400 64h-48V16c0-8.8-7.2-16-16-16h-32c-8.8 0-16 7.2-16 16v48H160V16c0-8.8-7.2-16-16-16h-32c-8.8 0-16 7.2-16 16v48H48C21.5 64 0 85.5 0 112v48h448v-48c0-26.5-21.5-48-48-48z"></path></svg>Jun 6<!-- --> Â· <!-- -->12 min read</span></section><article class="BlogPost--post_content--1ZOta"><h1>Introduction</h1>
<hr>
<div class="custom-block snippet"><div class="custom-block-body"><p>In the last part I talked about various ways of representing word as vectors in NLP. However, most state-of-the-art models (as of 2020 anyway) do not even care about word vectors at all! So what happened?</p></div></div>
<p>It should be obvious that using word vectors leave out an important aspect of all languages: word context. Words should not be treated individually, because a single word can have multiple and vastly different meanings in different contexts - consider <code class="language-text">content</code> in <code class="language-text">table of contents</code> and <code class="language-text">I am content with my job</code>.</p>
<p>In the end, most applications of NLP would require using sentences or even paragraphs or documents level representations. Examining word vectors remain mostly useful for analyzing and validating linguistic properties. That's why this part will probably drag out way longer than the first.</p>
<h1>Progress on sentence representation</h1>
<hr>
<h1>1. Bag of Words</h1>
<p>The original bag of words model involve counting occurences of words and putting inside a fixed-size dictionary vector. This is one-hot encoding on the sentence level - as illustrated below:</p>
<p>A dictionary such as:</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token punctuation">[</span><span class="token string">"the"</span><span class="token punctuation">,</span> <span class="token string">"quick"</span><span class="token punctuation">,</span> <span class="token string">"brown"</span><span class="token punctuation">,</span> <span class="token string">"fox"</span><span class="token punctuation">,</span> <span class="token string">"jumps"</span><span class="token punctuation">,</span> <span class="token string">"dog"</span><span class="token punctuation">,</span> <span class="token string">"like"</span><span class="token punctuation">]</span></code></pre></div>
<p>Would represent the sentence <code class="language-text">I like dog but I do not like fox</code> (forgive the grammar, it's beside the point) as:</p>
<table>
<thead>
<tr>
<th align="center">the</th>
<th align="center">quick</th>
<th align="center">brown</th>
<th align="center">fox</th>
<th align="center">jumps</th>
<th align="center">dog</th>
<th align="center">like</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">2</td>
</tr>
</tbody>
</table>
<p>Which is actually the sum of one-hot encoded word vectors!</p>
<p>Using word vectors, the bag of words model is either the sum or the average of word vectors - not necessarily one-hot encoded vectors, but often the pre-trained Word2Vec, GloVe or FastText vectors I mentioned in <a href="/blog/2020-05-27-brief-history-of-nlp.md">part 1</a>.</p>
<p>As immediately evident, this method disregards contextual information and word ordering. Used for sentence/document classification, it would be a glorified checking substrings algorithm.</p>
<h2>SIF and FastText</h2>
<p>One attempt to improve upon this method is to use a weighted average instead. This can be considered a direct improvement over removing stop words - we can use TF-IDF weighting scheme to determine the weights of word vectors, or a improved version - <em>smooth inverse frequency</em> (SIF). This method is implemented in <em>A simple but tough-to-beat baseline for sentence embeddings</em> - which actually outperforms several more complex models that actually takes into account word ordering (*on select tasks) - some of which we will explore later on in this article.</p>
<ul>
<li>Implementation: <a href="https://github.com/PrincetonML/SIF">PrincetonML /
SIF (Github)</a></li>
</ul>
<p>If you tried to <em>google</em> for FastText, you might also have seen the paper <em>Bag of Tricks for Efficient Text Classification</em> . This paper actually employs a similar method to vanilla bag of words - to take a (normal) average of word vectors. The difference here is it also encodes n-grams of words as separate tokens, which gives it a form of word order information.</p>
<p>For example, the following sentence:</p>
<p><code class="language-text">The quick brown fox jumps</code></p>
<p>Can be broken into these tokens (assuming a 2-gram model):</p>
<p><code class="language-text">&lt;the&gt;, &lt;quick&gt;, &lt;brown&gt;, &lt;fox&gt;, &lt;jumps&gt;, &lt;the quick&gt;, &lt;quick brown&gt;, &lt;brown fox&gt;, &lt;fox jumps&gt;</code></p>
<p>Then encoded and averaged into a sentence vector.</p>
<ul>
<li>Tutorial: <a href="https://fasttext.cc/docs/en/supervised-tutorial.html">Text classification using FastText</a></li>
<li>An approximate implementation that can give a good understanding on how FastText works lie in the <a href="https://keras.io/examples/imdb_fasttext/">Keras examples</a>.</li>
<li>Pytorch also has an implementation of this method in its <a href="https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html">examples documentation</a></li>
</ul>
<p>A honorable mention: this method bears homeage to <em>Convolutional Neural Networks for Sentence Classification</em>, where the use of convolutional network bears resemblance to this method of taking n-grams into account. Though empirically, this method of using CNNs might not necessarily outperform the various Bag-of-Words variations above, and is more computationally expensive.</p>
<p>References:</p>
<ul>
<li><a href="https://openreview.net/pdf?id=SyK00v5xx">A simple but tough-to-beat baseline for sentence embeddings</a></li>
<li><a href="https://arxiv.org/pdf/1607.01759.pdf">Bag of Tricks for Efficient Text Classification</a></li>
<li><a href="https://www.aclweb.org/anthology/D14-1181.pdf">Convolutional Neural Networks for Sentence Classification</a></li>
</ul>
<h1>2. Skip-Thought Vectors</h1>
<p>Note that by this time - People are not longer strangers to using recurrent networks (GRU/LSTM) for machine translation. This is, to my knowledge, the first attempt on applying Machine Translation to self-supervised training. The paper also introduces <em>BookCorpus</em>, which is a dataset that is often used to this day in combination with Wikipedia for training language models.</p>
<p>The training objective of Skip-Thought Vectors is to generate (or "translate") the previous and following sentence for any given sentence (similar to Word2Vec's skip-gram setup), as illustrated below:</p>
<p><figure class="gatsby-resp-image-figure" style="">
    <span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 881px;"
    >
      <a
    class="gatsby-resp-image-link"
    href="/static/32c4a4588d2910730aa54ad9bd4ce9a2/96658/brief-history-of-nlp-p2-skip-thought-objective.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 20.161290322580648%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsSAAALEgHS3X78AAAAh0lEQVQY062Pyw7CIBQF+f9/LGArUF7GpLYxhXZEXLsw8SaTOTlndQV/vLMhaq3s+04ppfsbn71wzzfCNDGPI77ZKoXVmnEYuFmLWNcV7wMxps47p5QJITYncs6tj6333VJKxovGWYMxV7SSqMZjWXhuG+LXt0ot+OhxYSakgPMOM1uO8+j7Cwg9NUzWum1jAAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Skip-Thought Vectors training objective"
        title="Skip-Thought Vectors training objective"
        src="/static/32c4a4588d2910730aa54ad9bd4ce9a2/96658/brief-history-of-nlp-p2-skip-thought-objective.png"
        srcset="/static/32c4a4588d2910730aa54ad9bd4ce9a2/544ba/brief-history-of-nlp-p2-skip-thought-objective.png 248w,
/static/32c4a4588d2910730aa54ad9bd4ce9a2/bb630/brief-history-of-nlp-p2-skip-thought-objective.png 496w,
/static/32c4a4588d2910730aa54ad9bd4ce9a2/96658/brief-history-of-nlp-p2-skip-thought-objective.png 881w"
        sizes="(max-width: 881px) 100vw, 881px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
      />
  </a>
    </span>
    <figcaption class="gatsby-resp-image-figcaption"><p>Skip-Thought Vectors training objective</p></figcaption>
  </figure></p>
<p>Side note: This paper also introduces an <em>interesting</em> technique for handling unseen words: It trains a linear mapping between Word2Vec and its encoder's embeddings layer for shared words. After that, unseen words can be taken from Word2Vec and mapped to the model's embedding space. This does seem to work decently from the examples given by the paper.</p>
<p>All in all, the 2 most important contributions of this work is the BookCorpus dataset and it paved the way for sentence embeddings by proving that it can outperform existing techniques. It demonstrated the viability of training a sentence-level encoder that's able to perform transfer learning and benefits downstream tasks (with obvious parallels to ImageNet). However, Skip-Thought was a huge model for its time (Bi-directional LSTM, 4096 dims and trained for a month), and it was quickly demonstrated that the training objective used in the paper was actually excessive, as the trend for the researches that follow gear towards computational efficiency.</p>
<h2>Quick-Thought Vectors</h2>
<p>With Skip-Thought vectors being the giant model that it is (even with now - in 2020 terms of hardware), the focus then shifted to finding ways to achieve the same sentence-vector results. Quick-Thought Vectors first demonstrated that a 3-way classifier can perform just as well - or even better, while being able to train much, much faster.</p>
<h3>Important side note:</h3>
<p>The reason for this faster training speed will be very relevant later on, so it's important to keep in mind: one of the biggest bottlenecks for NLP networks is very often the <em>Softmax layer</em>. The softmax operation is heavily used for classification. In the case of machine translation, the model actually <em>classifies</em> the next word - so there are as many classes as there are words in the vocabulary - which usually goes up to 20.000, 30.000 to 50.000 words at the time.</p>
<p>For translation, this also repeats for as many times as the decoded sentence's length. Hence why, with Quick-Thought being able to reduce this to only 3 classes, massively sped up the training process.</p>
<h2>InferSent</h2>
<p>This paper by Facebook AI Research (massive props to them) is actually not a great achievement in the grand scheme of things, but I find the paper interesting to read because the idea is simple and because of how extensively the authors evaluated alternatives (and spoiler: finding the simple bi-directional LSTM outperforming more complex methods). They also forgoes the Embedding layers in favor of vanilla word vectors, which massively reduces the size of the model and time to train: The model can be trained on a single consumer-grade GPU within a day.</p>
<p>The model is conceptually extremely simple: Word vectors > 2-layer Bi-directional LSTM > feed-forward and 3-way classifier, trained on NLI/SNLI datasets (which labels pairs of sentences on whether it entails each other, contradicts, or neutral). The problem with this model is that it's <em>supervised</em>. A good labelled dataset such as NLI/SNLI is obviously hard to obtain for other languages than English.</p>
<p><em>Side note:</em> I absolutely recommend digging up the repository's commit history to find the original implementation with the alternative encoders and training code like <a href="https://github.com/facebookresearch/InferSent/blob/bcc794990d40774698ab492d29396721ae0b2f9c/models.py">here</a>.</p>
<p>References:</p>
<ul>
<li><a href="https://arxiv.org/pdf/1506.06726">Skip-Thought Vectors</a></li>
<li><a href="https://arxiv.org/pdf/1803.02893.pdf">An Efficient Framework for Learning Sentence Representations</a></li>
<li><a href="https://arxiv.org/pdf/1705.02364">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</a></li>
</ul>
<h1>3. Language Models</h1>
<p>Language Models are a class of models which objective is to predict the next word (or character) in a sentence - think of the auto keyboard suggestions on modern smartphones. These models can be trained efficiently because each training batch is usually dense. They can also be trained in an unsupervised manner: as long as there is text you can train a language model on it.</p>
<p>Summary of the training task:
Source: The quick brown fox jumps over the lazy
Target: quick brown fox jumps over the lazy dog</p>
<p>These are some of the easiest class of models to implement, so they are also good for benchmarks on sequence networks. As such, later on I will also mention when it is used for Transformer-type networks.</p>
<p>As can be seen, because of the training task, language models are uni-directional, which means at every timestep, the meaning of the word is only considered by taking into account words <em>before</em> it and not after. There is one workaround by concatenating results from a left-to-right <em>and</em> right-to-left models, but they are not strictly bidirectional. Emperically, there is always performance to be gained from changing a unidirectional model to a bidirectional model.</p>
<p>Despite that, over the years, it was proven that unidirectional language models <em>can</em> be both easy to train and enough adequate to be used for transfer learning. For the LSTM era, this was most prominently demonstrated and pushed forward thanks to the following papers:</p>
<h2>Regularizing and Optimizing LSTM Language Models (AWD-LSTM - Salesforce)</h2>
<p>This paper demonstrated that a heavily regularized and hyperparameter-searched language model can greatly outperform naive counterparts. It also demonstrates a language model trained within a day on consumer-grade GPU. However, despite its touting a new recurrent network variant QRNN as a drop-in replacement for LSTM, QRNN quickly became unpopular due to its expressiveness being inferior to LSTM. However, it became an important starter codebase and baselines for a plethora of models that come out after.</p>
<h2>Universal Language Model Fine-tuning for Text Classification (ULMFIT - Fast.ai)</h2>
<p>This paper quickly became a standard as it demonstrated ways to train a language model efficiently and how to, afterwards, apply to downstream classification tasks with impressive results, with just small modifications to existing code. It popularized tricks such as linear warmup-decay learning rate schedule and "gradual unfreezing" when training on downstream classification. Unfortunately it never became too popular because ELMo (which I detailed in part 1 of the series) was released very soon after and became the new standard thanks to its superior performance. However, to this day, ULMFIT can still be considered as a quick and dirty baseline to any classification tasks.</p>
<p>References:</p>
<ul>
<li><a href="https://arxiv.org/pdf/1708.02182">Regularizing and Optimizing LSTM Language Models</a></li>
<li><a href="https://arxiv.org/pdf/1801.06146">Universal Language Model Fine-tuning for Text Classification</a></li>
</ul>
<h1>4. Other improvements</h1>
<p>Around this time, various other non-architectural tricks have also been employed and incorporated into models. These are just as important in terms of efficiency, and some are still widely used.</p>
<h2>Sub-word and Byte-pair encoding tokenization</h2>
<p>Sub-word segmentation and BPE has become a standard to solve the out-of-vocabulary issue. For a bit of background: in the word vector era, pre-trained word vectors would have in the 800k - 6 <em>billion</em> words. It was simply not viable in terms of computational and memory resources to use that many classes for neural network models. Therefore all models with embedding layers usually reduce this vocabulary size to around 50k or even 20k most common words. This often leaves words that don't exist in the vocabulary and would often have to be replaced with a representative <code class="language-text">_unknown_</code> token.</p>
<p>Sub-word segmentation is a mid-ground workaround for the issue: For example, by segmenting <code class="language-text">&quot;performer&quot;</code> into <code class="language-text">&quot;perform##&quot;</code> and <code class="language-text">&quot;##er&quot;</code>, and <code class="language-text">&quot;player&quot;</code> into <code class="language-text">&quot;play##&quot;</code> and <code class="language-text">&quot;##er&quot;</code>, we can reuse the token <code class="language-text">&quot;##er&quot;</code> that the 2 words share, and also use the token <code class="language-text">&quot;perform##&quot;</code> for <code class="language-text">&quot;perform##&quot;</code>+<code class="language-text">&quot;##ance&quot;</code>. This also potentially helps embed prefix and subfix grammatical meanings (e.g <code class="language-text">&quot;-er&quot;</code> usually represents people) into the model.</p>
<p>The solution is not perfect - however - there can still be out-of-vocabulary tokens and there are cases where the segmentation algorithm cannot work perfectly.</p>
<p><em>Side note</em>: Character-level models would obviously be the way to perfect representations that will have no out-of-vocabulary issue - hence it was actually employed partly in ELMo. However, this would significantly increase the tokens count in each sentence, which is both computationally expensive and causes forgetting in LSTM networks, which generally leads to inferior performance compared to word-level or subword-level models.</p>
<h2>Weight-tying for embeddings</h2>
<p>Normally, language models are extremely similar to neural machine translation models - save for one part: the input and output vocabulary are the same for language models. Since the output layer is usually a linear (vocabulary size x hidden size) layer, which is often the shape of the embedding layer, their weights can be tied to save a lot on memory consumption and provides a small regularization effect. This trick was employed in AWD-LSTM.</p>
<h2>Adaptive softmax</h2>
<p>By dividing softmax classes into smaller clusters, exploiting natural word distribution, this trick helps massively speed up softmax computation on GPUs for vocabulary size of around 50k and over. This can massively help training neural machine translation models and language models on consumer-grade GPUs. It has reduced efficiency for smaller vocabulary sizes, however, hence it is not often employed in recent models where the vocabulary size often settles at around 30k.</p>
<p>References:</p>
<ul>
<li><a href="https://arxiv.org/pdf/1508.07909">Neural Machine Translation of Rare Words with Subword Units</a></li>
<li><a href="https://arxiv.org/pdf/1910.13267">BPE-Dropout: Simple and Effective Subword Regularization</a></li>
<li><a href="https://arxiv.org/pdf/1608.05859.pdf">Using the Output Embedding to Improve Language Models</a></li>
<li><a href="https://arxiv.org/pdf/1609.04309">Efficient softmax approximation for GPUs</a></li>
</ul>
<p>In the next part of the series, I will discuss on Transformer models - which have been the state-of-the-art for the past few years and being all the hype in NLP to this day, which I feel should warrant it a dedicated article. Stay tuned!</p></article><section><div shortname="luungoc2005" config="[object Object]" id="disqus_thread"></div></section></section></div></div><div class="Footer--footer--3N4oY"><section class="Container--container--3QHbe"><div class="Footer--footer__content--3FUJz"><a href="https://luungoc2005.github.io" target="_blank" rel="noopener noreferrer"></a><ul class="Footer--footer__list--3m4JX"><li class="Footer--footer__item--31NlX"><a alt="Twitter" href="https://twitter.com/luungoc2005" target="_blank" rel="noopener noreferrer"><svg width="20px" height="15px" viewBox="0 0 20 15" version="1.1"><title>Twitter</title><defs></defs><g id="Good-One" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Footer_06" transform="translate(-1091.000000, -3948.000000)" fill="#9EA0A6"><g id="Group-7" transform="translate(0.000000, 3204.000000)"><g id="Group-6" transform="translate(75.000000, 733.000000)"><g id="dribbble" transform="translate(976.000000, 9.000000)"><path d="M53.2813915,2 C51.0959361,2 49.3247358,3.69382235 49.3247358,5.78774534 C49.3247358,6.08310267 49.3596502,6.37374182 49.4275918,6.64928284 C46.1380851,6.48980876 43.2222572,4.98471314 41.2708228,2.68885254 C40.9301711,3.25031454 40.7357826,3.90142174 40.7357826,4.59593608 C40.7357826,5.91041772 41.4331278,7.07014343 42.4956593,7.74672874 C41.8464394,7.72974333 41.236852,7.55800201 40.7027554,7.27396829 C40.7027554,7.29001007 40.7027554,7.30605184 40.7027554,7.32303724 C40.7027554,9.157461 42.066306,10.6880347 43.8771389,11.0362355 C43.5449799,11.1221062 43.1958354,11.1692879 42.8344238,11.1692879 C42.5796427,11.1692879 42.331467,11.1447534 42.0898968,11.1032335 C42.5937972,12.603611 44.0554857,13.7038878 45.7870533,13.7331404 C44.4319955,14.7447157 42.7259059,15.3552466 40.8726095,15.3552466 C40.5527177,15.3552466 40.237544,15.3344867 39.9280322,15.3014595 C41.6794162,16.3753145 43.7591847,17 45.9937091,17 C53.2719552,17 57.2522018,11.2287368 57.2522018,6.22464771 C57.2522018,6.06328636 57.2484273,5.89720684 57.2408782,5.73490186 C58.0146578,5.20080523 58.6855813,4.53648717 59.2159034,3.7768621 C58.5062909,4.07505033 57.7438349,4.27887519 56.9436336,4.37135128 C57.7598767,3.90142174 58.3873931,3.16066935 58.6827504,2.27648465 C57.9184071,2.70961248 57.0710242,3.02478611 56.1707977,3.19369653 C55.4479743,2.45954957 54.4203573,2 53.2813915,2" id="Fill-1"></path></g></g></g></g></g></svg></a></li><li class="Footer--footer__item--31NlX"><a alt="Github" href="https://github.com/luungoc2005" target="_blank" rel="noopener noreferrer"><svg height="17" viewBox="0 0 18 17" width="18"><title>Github</title><path d="m195.711029 1c-4.810968 0-8.711029 3.90006063-8.711029 8.71102924 0 3.85027496 2.500065 7.11691086 5.958344 8.27547776.435551.0696883.574928-.2003537.574928-.4355514 0-.2003537 0-.7491486 0-1.472164-2.412955.5226618-2.926906-1.1672779-2.926906-1.1672779-.400707-1.0104794-.966924-1.2805213-.966924-1.2805213-.792704-.5400838.060977-.5226618.060977-.5226618.871103.0609772 1.332788.8972361 1.332788.8972361.757859 1.3240764 2.03838.9320801 2.534909.7230154.078399-.5662169.304886-.9495022.548795-1.1672779-1.933849-.2177758-3.963518-.9669243-3.963518-4.28582642 0-.96692425.331019-1.74220585.897236-2.36068893-.087111-.21777573-.391997-1.12372277.08711-2.29971172 0 0 .731726-.23519779 2.395533.88852499.688171-.19164265 1.43732-.28746397 2.177757-.28746397.740438 0 1.489586.09582132 2.177758.28746397 1.663806-1.12372278 2.395533-.88852499 2.395533-.88852499.479106 1.17598895.17422 2.08193599.08711 2.29971172.566217.61848308.897236 1.39376468.897236 2.36068893 0 3.32761312-2.038381 4.05933962-3.98094 4.27711532.313597.2700419.601061.8014147.601061 1.6115404v2.3868221c0 .2351977.139376.5139507.583639.4355514 3.458278-1.1672779 5.949632-4.4252028 5.949632-8.27547776 0-2.3103086-.917766-4.52599297-2.551401-6.15962785-1.633635-1.63363487-3.849319-2.55140139-6.159628-2.55140139z" fill="#9ea0a6" transform="translate(-187 -1)"></path></svg></a></li><li class="Footer--footer__item--31NlX"><a alt="Facebook" href="https://www.facebook.com/luungoc2005" target="_blank" rel="noopener noreferrer"><svg width="9px" height="18px" viewBox="0 0 9 18" version="1.1"><title>Facebook</title><defs></defs><g id="Good-One" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Footer_06" transform="translate(-1051.000000, -3946.000000)" fill="#9EA0A6" fill-rule="nonzero"><g id="Group-7" transform="translate(0.000000, 3204.000000)"><g id="Group-6" transform="translate(75.000000, 733.000000)"><g id="dribbble" transform="translate(976.000000, 9.000000)"><path d="M9,0 L9,3.6 L7.2,3.6 C6.579,3.6 6.3,4.329 6.3,4.95 L6.3,7.2 L9,7.2 L9,10.8 L6.3,10.8 L6.3,18 L2.7,18 L2.7,10.8 L0,10.8 L0,7.2 L2.7,7.2 L2.7,3.6 C2.7,1.6117749 4.3117749,3.99680289e-16 6.3,0 L9,0 Z" id="Shape"></path></g></g></g></g></g></svg></a></li><li class="Footer--footer__item--31NlX"><a alt="LinkedIn" href="https://www.linkedin.com/in/luungoc2005/" target="_blank" rel="noopener noreferrer"><svg width="18" height="18" viewBox="0 0 18 18"><title>
    LinkedIn
  </title><path fill="#9EA0A6" fill-rule="nonzero" d="M18 18h-4v-6.75c0-1.06-1.19-1.94-2.25-1.94S10 10.19 10 11.25V18H6V6h4v2c.66-1.07 2.36-1.76 3.5-1.76 2.5 0 4.5 2.04 4.5 4.51V18zM4 18H0V6h4v12zM2 0a2 2 0 1 1 0 4 2 2 0 0 1 0-4z"></path></svg></a></li></ul></div></section></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  
  if(!(parseInt(navigator.doNotTrack) === 1 || parseInt(window.doNotTrack) === 1 || parseInt(navigator.msDoNotTrack) === 1 || navigator.doNotTrack === "yes")) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-87659525-1', 'auto', {});
      
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/2020-06-06-brief-history-of-nlp-p2/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-d996fbcb14d4968f7635.js"],"component---src-components-blog-post-blog-post-tsx":["/component---src-components-blog-post-blog-post-tsx-47ff1ab6a59cdc040003.js"],"component---src-pages-404-tsx":["/component---src-pages-404-tsx-925e542d3602a43354d0.js"],"component---src-pages-about-tsx":["/component---src-pages-about-tsx-33c8ed2be3cd074d478a.js"],"component---src-pages-blog-tsx":["/component---src-pages-blog-tsx-619e41220d75c9aaf86c.js"],"component---src-pages-index-tsx":["/component---src-pages-index-tsx-60a351ec886ef64c5d32.js"]};/*]]>*/</script><script src="/component---src-components-blog-post-blog-post-tsx-47ff1ab6a59cdc040003.js" async=""></script><script src="/styles-8636a280cbc61d53ad10.js" async=""></script><script src="/app-d996fbcb14d4968f7635.js" async=""></script><script src="/framework-5dd3c501fd049989ea3a.js" async=""></script><script src="/webpack-runtime-4f6fc807c3862521eb29.js" async=""></script></body></html>