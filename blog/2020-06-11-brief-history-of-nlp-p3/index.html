<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.44b15bc2c74f1d534d14.css" data-identity="gatsby-global-css">.Header-module--header--Wcvsx{display:block}.Header-module--header__container--FQQsy{flex-grow:1;margin:0 auto;max-width:1320px;padding-left:30px;padding-right:30px}@media(min-width:420px){.Header-module--header__container--FQQsy{max-width:1350px}}@media(min-width:720px){.Header-module--header__container--FQQsy{max-width:1390px;padding-left:50px;padding-right:50px}}@media(min-width:1080px){.Header-module--header__container--FQQsy{max-width:1430px;padding-left:70px;padding-right:70px}}.Header-module--header__content--Lz0RY{align-items:center;display:flex;padding:30px 0}.Header-module--header__logo--O4AxC{color:#333;text-decoration:none}.Header-module--header__logoSvg--\+o3hC{display:block;height:16px;width:auto}@media(min-width:768px){.Header-module--header__logoSvg--\+o3hC{height:18px}}.Header-module--header__logo--O4AxC h1{display:block;font-size:medium;font-weight:600}@media(min-width:768px){.Header-module--header__logo--O4AxC h1{display:inline-block;font-size:large}}.Header-module--header__logo--O4AxC span{color:#666;display:none}@media(min-width:768px){.Header-module--header__logo--O4AxC span{display:initial;padding-left:8px}}.Header-module--header__navigation--IcX3m{display:flex;margin-left:auto}.HeaderLink-module--link--2ew99{color:#404040;display:flex;margin-left:40px;text-decoration:none;transition:opacity .2s ease-in-out}.HeaderLink-module--link--2ew99:first-of-type{margin-left:0}.HeaderLink-module--link--2ew99:hover{opacity:.5}.HeaderLink-module--link__icon--cUb1K{margin-right:8px;position:relative}.HeaderLink-module--link__icon--cUb1K path{fill:#404040}@media(min-width:768px){.HeaderLink-module--link__icon--cUb1K{top:3px}}.Container-module--container--37L5Z{flex-grow:1;margin:0 auto;max-width:1320px;padding-left:30px;padding-right:30px}@media(min-width:420px){.Container-module--container--37L5Z{max-width:1350px}}@media(min-width:720px){.Container-module--container--37L5Z{max-width:1390px;padding-left:50px;padding-right:50px}}@media(min-width:1080px){.Container-module--container--37L5Z{max-width:1430px;padding-left:70px;padding-right:70px}}.Footer-module--footer--iTLBh{bottom:0;left:0;position:absolute;right:0}.Footer-module--footer__content--ZBH5p{border-bottom:10px solid #8effbf;display:flex;justify-content:space-between;padding:40px 0}.Footer-module--footer__list--EQmCA{display:flex}.Footer-module--footer__item--cL2qa{margin-left:30px;transition:opacity .2s ease-in-out}.Footer-module--footer__item--cL2qa:hover{opacity:.5}:root{--grid-column-count:12;--grid-baseline:16px;--grid-baseline-calc:unitless($grid-baseline)}.GridOverlay-module--grid--8VUqK{bottom:0;left:0;overflow:hidden;pointer-events:none;position:absolute;right:0;top:0;-webkit-transform-origin:50% 0;transform-origin:50% 0;z-index:10000}.GridOverlay-module--grid__container--vwZSa{flex-grow:1;height:100%;margin:0 auto;max-width:1320px;opacity:0;padding-left:30px;padding-right:30px;transition:opacity .2s}@media(min-width:420px){.GridOverlay-module--grid__container--vwZSa{max-width:1350px}}@media(min-width:720px){.GridOverlay-module--grid__container--vwZSa{max-width:1390px;padding-left:50px;padding-right:50px}}@media(min-width:1080px){.GridOverlay-module--grid__container--vwZSa{max-width:1430px;padding-left:70px;padding-right:70px}}.GridOverlay-module--grid--8VUqK.GridOverlay-module--isVerticalVisible--5Q1Qq .GridOverlay-module--grid__container--vwZSa{opacity:1}.GridOverlay-module--gridIsHorizontalIsVisible--dR7F4{background:linear-gradient(to bottom,transparent calc(100% - 1/var(--grid-baseline-calc)*100%),rgba(0,0,0,.05) calc(100% - 1/var(--grid-baseline-calc)*100%)),linear-gradient(to bottom,transparent calc(100% - 1/var(--grid-baseline-calc)*100%),hsla(0,0%,100%,.15) calc(100% - 1/var(--grid-baseline-calc)*100%));background-size:var(--grid-baseline) var(--grid-baseline)}.GridOverlay-module--grid__row--kfinc{align-items:stretch;display:flex;flex-direction:row;flex-wrap:wrap;height:100%;justify-content:flex-start;margin-left:-15px;margin-right:-15px}.GridOverlay-module--grid__column--KejkO{align-self:stretch;flex:none;height:100%;padding-left:15px;padding-right:15px;position:relative;width:calc(100%/var(--grid-column-count, 12))}.GridOverlay-module--grid__visualize--MxssM{height:100%;position:relative;width:100%}.GridOverlay-module--grid__visualize--MxssM:after,.GridOverlay-module--grid__visualize--MxssM:before{background-color:hsla(0,0%,100%,.1);content:"";display:block;height:100%;width:100%}.GridOverlay-module--grid__visualize--MxssM:after{background-color:rgba(0,0,0,.05);left:0;position:absolute;top:0}.GridOverlay-module--grid__button--FHIrj{background-color:#fff;border:1px solid rgba(0,0,0,.1);border-radius:0 0 2px 2px;border-top:0 solid rgba(0,0,0,.1);color:#999;cursor:pointer;font-size:12px;height:26px;opacity:1;padding:0 15px;pointer-events:all;position:fixed;right:75px;text-transform:uppercase;top:0;transition:opacity .25s,-webkit-transform .1s;transition:opacity .25s,transform .1s;transition:opacity .25s,transform .1s,-webkit-transform .1s;z-index:10000}.GridOverlay-module--grid__button--FHIrj:hover{color:#000}.GridOverlay-module--grid__button--FHIrj:hover g{fill:#000}.GridOverlay-module--grid__button--FHIrj:first-of-type{right:131px}.GridOverlay-module--grid__button__svg--8W5Pm{margin-top:4px}.GridOverlay-module--grid__button__svg--8W5Pm g{fill:#8d8d8d}.GridOverlay-module--grid__button--FHIrj.GridOverlay-module--horizontal--Kz\+nn:hover g,.GridOverlay-module--grid__button--FHIrj.GridOverlay-module--horizontal--Kz\+nn g,.GridOverlay-module--grid__button--FHIrj.GridOverlay-module--vertical--175C7 g,.GridOverlay-module--grid__button--FHIrj.GridOverlay-module--vertical--175C7:hover g{fill:#328bf3}[data-columns="1"] .GridOverlay-module--grid__column--KejkO{min-width:100%}[data-columns="2"] .GridOverlay-module--grid__column--KejkO{min-width:50%}[data-columns="3"] .GridOverlay-module--grid__column--KejkO{min-width:33.3333333333%}[data-columns="4"] .GridOverlay-module--grid__column--KejkO{min-width:25%}[data-columns="5"] .GridOverlay-module--grid__column--KejkO{min-width:20%}[data-columns="6"] .GridOverlay-module--grid__column--KejkO{min-width:16.6666666667%}[data-columns="7"] .GridOverlay-module--grid__column--KejkO{min-width:14.2857142857%}[data-columns="8"] .GridOverlay-module--grid__column--KejkO{min-width:12.5%}[data-columns="9"] .GridOverlay-module--grid__column--KejkO{min-width:11.1111111111%}[data-columns="10"] .GridOverlay-module--grid__column--KejkO{min-width:10%}[data-columns="11"] .GridOverlay-module--grid__column--KejkO{min-width:9.0909090909%}[data-columns="12"] .GridOverlay-module--grid__column--KejkO{min-width:8.3333333333%}a,abbr,acronym,address,applet,article,aside,audio,b,big,blockquote,body,canvas,caption,center,cite,code,dd,del,details,dfn,div,dl,dt,em,embed,fieldset,figcaption,figure,footer,form,h1,h2,h3,h4,h5,h6,header,hgroup,hr,html,i,iframe,img,ins,kbd,label,legend,li,mark,menu,nav,object,ol,output,p,pre,q,ruby,s,samp,section,small,span,strike,strong,sub,summary,sup,table,tbody,td,tfoot,th,thead,time,tr,tt,u,ul,var,video{border:0;border-radius:0;font-family:inherit;font-size:inherit;font-style:inherit;font-weight:inherit;margin:0;padding:0}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:after,blockquote:before,q:after,q:before{content:"";content:none}table{border-collapse:collapse;border-spacing:0}button,input,select,textarea{-webkit-appearance:none;appearance:none;border:0;font-family:inherit;font-size:inherit;font-style:inherit;font-weight:inherit}button:focus:not(:focus-visible),input:focus:not(:focus-visible),select:focus:not(:focus-visible),textarea:focus:not(:focus-visible){outline:none}.container,.container-fluid{margin-left:auto;margin-right:auto}.container-fluid{padding-left:2rem;padding-right:2rem}.row{box-sizing:border-box;display:flex;flex:0 1 auto;flex-direction:row;flex-wrap:wrap;margin-left:-.5rem;margin-right:-.5rem}.row.reverse{flex-direction:row-reverse}.col.reverse{flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12{box-sizing:border-box;flex:0 0 auto;padding-left:.5rem;padding-right:.5rem}.col-xs{flex-basis:0;flex-grow:1;max-width:100%}.col-xs-1{flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{flex-basis:25%;max-width:25%}.col-xs-4{flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{flex-basis:50%;max-width:50%}.col-xs-7{flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{flex-basis:75%;max-width:75%}.col-xs-10{flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{justify-content:flex-start;text-align:start}.center-xs{justify-content:center;text-align:center}.end-xs{justify-content:flex-end;text-align:end}.top-xs{align-items:flex-start}.middle-xs{align-items:center}.bottom-xs{align-items:flex-end}.around-xs{justify-content:space-around}.between-xs{justify-content:space-between}.first-xs{order:-1}.last-xs{order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12{box-sizing:border-box;flex:0 0 auto;padding-left:.5rem;padding-right:.5rem}.col-sm{flex-basis:0;flex-grow:1;max-width:100%}.col-sm-1{flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{flex-basis:25%;max-width:25%}.col-sm-4{flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{flex-basis:50%;max-width:50%}.col-sm-7{flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{flex-basis:75%;max-width:75%}.col-sm-10{flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{justify-content:flex-start;text-align:start}.center-sm{justify-content:center;text-align:center}.end-sm{justify-content:flex-end;text-align:end}.top-sm{align-items:flex-start}.middle-sm{align-items:center}.bottom-sm{align-items:flex-end}.around-sm{justify-content:space-around}.between-sm{justify-content:space-between}.first-sm{order:-1}.last-sm{order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-10,.col-md-11,.col-md-12,.col-md-offset-0,.col-md-offset-1,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12{box-sizing:border-box;flex:0 0 auto;padding-left:.5rem;padding-right:.5rem}.col-md{flex-basis:0;flex-grow:1;max-width:100%}.col-md-1{flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{flex-basis:25%;max-width:25%}.col-md-4{flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{flex-basis:50%;max-width:50%}.col-md-7{flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{flex-basis:75%;max-width:75%}.col-md-10{flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{justify-content:flex-start;text-align:start}.center-md{justify-content:center;text-align:center}.end-md{justify-content:flex-end;text-align:end}.top-md{align-items:flex-start}.middle-md{align-items:center}.bottom-md{align-items:flex-end}.around-md{justify-content:space-around}.between-md{justify-content:space-between}.first-md{order:-1}.last-md{order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12{box-sizing:border-box;flex:0 0 auto;padding-left:.5rem;padding-right:.5rem}.col-lg{flex-basis:0;flex-grow:1;max-width:100%}.col-lg-1{flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{flex-basis:25%;max-width:25%}.col-lg-4{flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{flex-basis:50%;max-width:50%}.col-lg-7{flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{flex-basis:75%;max-width:75%}.col-lg-10{flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{justify-content:flex-start;text-align:start}.center-lg{justify-content:center;text-align:center}.end-lg{justify-content:flex-end;text-align:end}.top-lg{align-items:flex-start}.middle-lg{align-items:center}.bottom-lg{align-items:flex-end}.around-lg{justify-content:space-around}.between-lg{justify-content:space-between}.first-lg{order:-1}.last-lg{order:1}}:root{--scale-element:1;--scale-font:1}@media(max-height:920px){:root{--scale-element:0.975;--scale-font:0.975}}@media(max-height:800px){:root{--scale-element:0.95;--scale-font:0.95}}@media(max-height:690px){:root{--scale-element:0.925;--scale-font:0.925}}body,html{background-color:#fff;min-height:100vh}html{-webkit-overflow-scrolling:touch;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;overflow-x:hidden;overflow-y:scroll}*,:after,:before{box-sizing:inherit}body{-webkit-text-size-adjust:100%;-moz-text-size-adjust:100%;text-size-adjust:100%;color:#333;font-family:Roboto,sans-serif;font-size:13px;font-size:calc(13px*var(--scale-font));line-height:1.5;margin:0;position:relative}@media(min-width:420px){body{font-size:13px;font-size:calc((.29703vw + 11.75248px)*var(--scale-font))}}@media(min-width:1430px){body{font-size:16px;font-size:calc(16px*var(--scale-font))}}img{display:block;height:auto;max-width:100%}input::-webkit-input-placeholder,select::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#ddd}input::-moz-placeholder,select::-moz-placeholder,textarea::-moz-placeholder{color:#ddd;opacity:1}input:-ms-input-placeholder,select:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#ddd}a{color:#1a1a1a;font-weight:400;text-decoration:none;transition:opacity .2s ease-in-out}a:hover{opacity:.5}.AppLayout-module--layout--jfjNv{display:block;min-height:100vh}code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#000;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;text-align:left;white-space:pre;word-break:normal;word-spacing:normal}pre[class*=language-]{margin:.5em 0;overflow:visible;padding:0;position:relative}pre[class*=language-]>code{background-attachment:local;background-color:#fdfdfd;background-image:linear-gradient(transparent 50%,rgba(69,142,209,.04) 0);background-origin:content-box;background-size:3em 3em;border-left:10px solid #358ccb;box-shadow:-1px 0 0 0 #358ccb,0 0 0 1px #dfdfdf;position:relative}code[class*=language]{display:block;height:inherit;max-height:inherit;overflow:auto;padding:0 1em}:not(pre)>code[class*=language-],pre[class*=language-]{background-color:#fdfdfd;box-sizing:border-box;margin-bottom:1em}:not(pre)>code[class*=language-]{border:1px solid rgba(0,0,0,.1);border-radius:.3em;color:#c92c2c;display:inline;padding:.2em;position:relative;white-space:normal}pre[class*=language-]:after,pre[class*=language-]:before{bottom:.75em;box-shadow:0 13px 8px #979797;content:"";display:block;height:20%;left:.18em;max-height:13em;position:absolute;-webkit-transform:rotate(-2deg);transform:rotate(-2deg);width:40%;z-index:-2}:not(pre)>code[class*=language-]:after,pre[class*=language-]:after{left:auto;right:.75em;-webkit-transform:rotate(2deg);transform:rotate(2deg)}.token.block-comment,.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#7d8b99}.token.punctuation{color:#5f6364}.token.boolean,.token.constant,.token.deleted,.token.function-name,.token.number,.token.property,.token.symbol,.token.tag{color:#c92c2c}.token.attr-name,.token.builtin,.token.char,.token.function,.token.inserted,.token.selector,.token.string{color:#2f9c0a}.token.entity,.token.operator,.token.url,.token.variable{background:hsla(0,0%,100%,.5);color:#a67f59}.token.atrule,.token.attr-value,.token.class-name,.token.keyword{color:#1990b8}.token.important,.token.regex{color:#e90}.language-css .token.string,.style .token.string{background:hsla(0,0%,100%,.5);color:#a67f59}.token.important{font-weight:400}.token.bold{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.token.namespace{opacity:.7}@media screen and (max-width:767px){pre[class*=language-]:after,pre[class*=language-]:before{bottom:14px;box-shadow:none}}.token.cr:before,.token.lf:before,.token.tab:not(:empty):before{color:#e0d7d1}pre[class*=language-].line-numbers.line-numbers{padding-left:0}pre[class*=language-].line-numbers.line-numbers code{padding-left:3.8em}pre[class*=language-].line-numbers.line-numbers .line-numbers-rows{left:0}pre[class*=language-][data-line]{padding-bottom:0;padding-left:0;padding-top:0}pre[data-line] code{padding-left:4em;position:relative}pre .line-highlight{margin-top:0}.AboutColumn-module--about_col--vGngi{opacity:.7;padding:6px 0;transition:opacity .2s ease-in-out}.AboutColumn-module--about_col--vGngi ul{display:none}.AboutColumn-module--about_col--vGngi:hover{opacity:1}.AboutColumn-module--about_col__avatar--FfREI img{border:1px solid #f2f3f3;border-radius:50%;height:48px;padding:5px;width:48px}.AboutColumn-module--about_col__heading--6ULIu{font-family:Open Sans,sans-serif;font-size:22px;font-size:calc(22px*var(--scale-font));font-weight:300;margin-bottom:5px}@media(min-width:420px){.AboutColumn-module--about_col__heading--6ULIu{font-size:22px;font-size:calc((.39604vw + 20.33663px)*var(--scale-font))}}@media(min-width:1430px){.AboutColumn-module--about_col__heading--6ULIu{font-size:26px;font-size:calc(26px*var(--scale-font))}}.AboutColumn-module--about_col__desc_container--pczVC{margin-left:12px;padding:0}.AboutColumn-module--about_col__description--1IZO\+{font-style:italic;line-height:1.625;margin-bottom:5px}.AboutColumn-module--about_col__details--WsCUp{line-height:2;-webkit-user-select:none;-ms-user-select:none;user-select:none}.AboutColumn-module--about_col__details__icon--yKg4U{display:inline-block;width:28px}.AboutColumn-module--about_col__details__text--vP5Cr{font-weight:400;padding:8px 0}@media only screen and (min-width:48em){.AboutColumn-module--about_col--vGngi{max-width:100%;padding:60px 12px}.AboutColumn-module--about_col--vGngi ul{display:block}.AboutColumn-module--about_col__avatar--FfREI img{height:110px;width:110px}.AboutColumn-module--about_col__desc_container--pczVC{margin-left:0}.AboutColumn-module--about_col__heading--6ULIu{margin-bottom:12px}.AboutColumn-module--about_col__description--1IZO\+{margin-bottom:18px}}.PostsLayout-module--layout--eGkUk{min-height:100vh}.PostsLayout-module--side_bar--eH3NI{margin-left:auto;margin-right:auto}@media only screen and (min-width:48em){.PostsLayout-module--side_bar--eH3NI{margin-left:0;margin-right:0}}.PostsLayout-module--posts_content---0yRu{margin-bottom:128px;margin-left:12px;margin-right:24px;text-align:justify;width:100%}@media only screen and (min-width:48em){.PostsLayout-module--posts_content---0yRu{margin-left:0;margin-right:0}}.PostsLayout-module--posts_content---0yRu a{color:#497e60}.PostsLayout-module--posts_content---0yRu ol,.PostsLayout-module--posts_content---0yRu p,.PostsLayout-module--posts_content---0yRu ul{margin:0 0 1.3em}.PostsLayout-module--posts_content---0yRu h1{font-size:larger}.PostsLayout-module--posts_content---0yRu h1,.PostsLayout-module--posts_content---0yRu h2,.PostsLayout-module--posts_content---0yRu h3,.PostsLayout-module--posts_content---0yRu h4,.PostsLayout-module--posts_content---0yRu h5,.PostsLayout-module--posts_content---0yRu h6{font-weight:400;line-height:3em}.PostsLayout-module--posts_content---0yRu ol{list-style:decimal inside}.PostsLayout-module--posts_content---0yRu ul{list-style:inside}.PostsLayout-module--posts_content---0yRu em{font-style:italic}.PostsLayout-module--posts_content---0yRu strong{font-weight:400}.PostsLayout-module--posts_content---0yRu sup{font-size:small}.PostsLayout-module--posts_content---0yRu hr{border-bottom:1px solid #333;margin-bottom:8px}.PostsLayout-module--posts_content---0yRu table{border-collapse:collapse;border-spacing:.5rem;margin:18px 0;width:100%}.PostsLayout-module--posts_content---0yRu td,.PostsLayout-module--posts_content---0yRu th{border:thin solid #999;padding:.5em}.PostsLayout-module--posts_content---0yRu th{color:#479b6b;font-weight:400}.PostsLayout-module--posts_content---0yRu blockquote{border-left:.25em solid #666;font-style:italic;margin:2em 1em;padding-left:1em}.PostsLayout-module--posts_content---0yRu figcaption{font-size:.8em;margin:8px 0;text-align:center}div.gist-data{line-height:normal;max-height:500px}div.gist table{border-spacing:0}div.gist th,td{border:0!important;padding:.5em}div.gatsby-highlight{font-size:13px}.PageHeader-module--page_header---OFxr{border-bottom:1px solid #e5e5e5;padding:20px 0}.PageHeader-module--page_header__text--W8IV-{font-family:Open Sans,sans-serif;font-size:26px;font-size:calc(26px*var(--scale-font));font-weight:300}@media(min-width:420px){.PageHeader-module--page_header__text--W8IV-{font-size:26px;font-size:calc((.59406vw + 23.50495px)*var(--scale-font))}}@media(min-width:1430px){.PageHeader-module--page_header__text--W8IV-{font-size:32px;font-size:calc(32px*var(--scale-font))}}.BlogPost-module--post_meta--vvhwE{margin-top:36px}.BlogPost-module--post_meta--vvhwE span{font-weight:300}.BlogPost-module--post_meta--vvhwE span svg{margin-right:12px;width:.8em}.BlogPost-module--post_content--iLhZI{border-bottom:1px solid #e5e5e5;font-size:16px;font-size:calc(16px*var(--scale-font));font-weight:300;line-height:1.625;margin-bottom:20px;margin-top:20px;padding-bottom:20px}@media(min-width:420px){.BlogPost-module--post_content--iLhZI{font-size:16px;font-size:calc((.19802vw + 15.16832px)*var(--scale-font))}}@media(min-width:1430px){.BlogPost-module--post_content--iLhZI{font-size:18px;font-size:calc(18px*var(--scale-font))}}.Segment-module--segment--aNhkZ{flex-grow:1;padding-bottom:90px;padding-top:90px}@supports(--css:variables){.Segment-module--segment--aNhkZ{padding-bottom:calc(90px*var(--scale-element));padding-top:calc(90px*var(--scale-element))}}@media(min-width:720px){.Segment-module--segment--aNhkZ{padding-bottom:13.986013986%;padding-top:13.986013986%}@supports(--css:variables){.Segment-module--segment--aNhkZ{padding-bottom:calc(13.98601%*var(--scale-element));padding-top:calc(13.98601%*var(--scale-element))}}}@media(min-width:1430px){.Segment-module--segment--aNhkZ{padding-bottom:200px;padding-top:200px}@supports(--css:variables){.Segment-module--segment--aNhkZ{padding-bottom:calc(200px*var(--scale-element));padding-top:calc(200px*var(--scale-element))}}}.Row-module--row--yqBQJ{align-items:stretch;display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-start;margin-left:-15px;margin-right:-15px}.Intro-module--intro--XUFq1{border-bottom:1px solid #e5e5e5;padding:60px 0}@media(min-width:768px){.Intro-module--intro--XUFq1{padding:120px 0}}.Intro-module--intro__col--Phmmc{align-self:stretch;flex:none;padding-left:15px;padding-right:15px;width:100%}@media(min-width:768px){.Intro-module--intro__col--Phmmc{align-self:stretch;flex:none;padding-left:15px;padding-right:15px;width:58.3333333333%}}.Intro-module--intro__text--n9SsU{font-family:Open Sans,sans-serif;font-size:26px;font-size:calc(26px*var(--scale-font));font-weight:300}@media(min-width:420px){.Intro-module--intro__text--n9SsU{font-size:26px;font-size:calc((.59406vw + 23.50495px)*var(--scale-font))}}@media(min-width:1430px){.Intro-module--intro__text--n9SsU{font-size:32px;font-size:calc(32px*var(--scale-font))}}.Highlight-module--highlight--VbsxT{position:relative}.Highlight-module--highlight__text--nYAFM{position:relative;z-index:1}.Highlight-module--isFirst--NHgJ1 .Highlight-module--highlight__text--nYAFM{padding-right:10px}.Highlight-module--highlight__color--2VswU{background-color:rgba(142,255,191,.3);bottom:8px;height:16px;left:0;position:absolute;width:100%;z-index:0}.BlockText-module--block--gVFGf{padding:60px 0}@media(min-width:768px){.BlockText-module--block--gVFGf{padding:80px 0}}.BlockText-module--block__col--4wdYJ{align-self:stretch;flex:none;padding-left:15px;padding-right:15px;width:100%}@media(min-width:768px){.BlockText-module--block__col--4wdYJ{align-self:stretch;flex:none;padding-left:15px;padding-right:15px;width:41.6666666667%}.BlockText-module--block__col--4wdYJ.BlockText-module--full_width--oHgMY{align-self:stretch;flex:none;padding-left:15px;padding-right:15px;width:100%}}.BlockText-module--block__heading--wbZsf{font-family:Open Sans,sans-serif;font-size:16px;font-size:calc(16px*var(--scale-font));margin-bottom:10px}@media(min-width:420px){.BlockText-module--block__heading--wbZsf{font-size:16px;font-size:calc((.19802vw + 15.16832px)*var(--scale-font))}}@media(min-width:1430px){.BlockText-module--block__heading--wbZsf{font-size:18px;font-size:calc(18px*var(--scale-font))}}.BlockText-module--block__heading--wbZsf a{display:inline-block;margin-left:12px!important}.BlockText-module--block__description--jW\+D3{font-size:16px;font-size:calc(16px*var(--scale-font));font-weight:300;line-height:1.625}@media(min-width:420px){.BlockText-module--block__description--jW\+D3{font-size:16px;font-size:calc((.19802vw + 15.16832px)*var(--scale-font))}}@media(min-width:1430px){.BlockText-module--block__description--jW\+D3{font-size:18px;font-size:calc(18px*var(--scale-font))}}.BlockText-module--block__description--jW\+D3 a{color:#000;font-weight:400;text-decoration:none;transition:opacity .2s ease-in-out}.BlockText-module--block__description--jW\+D3 a:hover{opacity:.5}.BlockText-module--block__description--jW\+D3 p{margin-bottom:1.3em}.PostTag-module--post_tag--YLbwl{border:1px solid #999;border-radius:2px;color:#333;margin:1px 4px 1px 0;opacity:.8;padding:0 5px}.PostBrief-module--post_brief--719qr{border:1px solid #e6e6e6;border-radius:5px;box-shadow:0 10px 10px 0 rgba(50,128,122,.2);margin:12px 12px 24px;opacity:.8;padding:24px;transition:opacity .2s ease-in-out}.PostBrief-module--post_brief--719qr:hover{opacity:1}.PostBrief-module--post_brief--719qr:after{clear:both;content:"";display:table}.PostBrief-module--post_brief--719qr header{font-family:Open Sans,sans-serif;font-weight:300}.PostBrief-module--post_brief--719qr header a{font-weight:400;line-height:1.5rem}.PostBrief-module--post_brief--719qr header.PostBrief-module--small--0qfdt a{display:block;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.PostBrief-module--post_brief__meta--nh4SK{display:inline-block;font-size:.8em}.PostBrief-module--post_brief__meta--nh4SK svg{width:.8em}.PostBrief-module--post_brief__meta--nh4SK.PostBrief-module--small--0qfdt{display:block;margin-top:5px}.PostBrief-module--post_brief__content--6zqPR{font-family:Roboto,sans-serif;margin:12px 0;text-align:justify}.PostBrief-module--post_brief__content--6zqPR.PostBrief-module--small--0qfdt{line-height:24px;max-height:120px;overflow:hidden;text-overflow:ellipsis}.PostBrief-module--post_brief__back_top--ZhR-g{float:right;font-size:.8em;text-transform:uppercase}.PostBrief-module--post_brief__back_top--ZhR-g.PostBrief-module--small--0qfdt{display:none}.PublishedYear-module--published_year--IzEeR{font-family:Open Sans,sans-serif;font-size:18px;font-size:calc(18px*var(--scale-font));font-weight:300;margin:24px 12px 18px;padding:0 24px}@media(min-width:420px){.PublishedYear-module--published_year--IzEeR{font-size:18px;font-size:calc((.59406vw + 15.50495px)*var(--scale-font))}}@media(min-width:1430px){.PublishedYear-module--published_year--IzEeR{font-size:24px;font-size:calc(24px*var(--scale-font))}}</style><meta name="generator" content="Gatsby 4.3.0"/><link rel="preconnect" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><title data-react-helmet="true">A history of progress on text representation in NLP (Part 3 - Transformer models) - Ngoc Nguyen&#x27;s Personal Blog</title><link data-react-helmet="true" rel="icon" type="image/x-icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAA8CAMAAAANIilAAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAKVQTFRFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA////VEBv8wAAADV0Uk5TAAIGCAMeR2qRrbyPaUic1fdCPafu7KYZjeorr/2uJjjNyAX+6e2EH9OQvQGbg0PrOo7HCTmYrbJMAAAAAWJLR0Q2R7+I0QAAAAlwSFlzAAAASAAAAEgARslrPgAAASxJREFUSMftlmtTgzAQRUlSbFMIYKoU2tLWPihStVrd///XfIwzjiObTQkzfuF8P5PsEO5dz+vp+S8YF4KzFuLAvxqO5Hgsg1D5g4tUoaI4gW+SOLoW1irXkxv4xW2quZ07zXL4Q55NbdzZfAENLIol7a7WgHC3Is9FXYD1jJi3AAOFce5NtjXJ22xjkPUOjOw07ooUCFL8tag9Je/Ro1lEuQAlJh9iWq4O2K0TWk4UIoe0CxAiI9/byKPmdODSRpbN/6aobeRadC87XfsY2MjBsftP5fZInJ4ne6DlRw/j6US5+TMqO4WBUwyRAfhiCkCn6PW85Rl3z2ThuNQNXnRzi6Jzq9imcj9NbMv9g1ddVj9rRVW+2a8Vn7CvhaauZTBUfpuNqPUq1dPTDe+aneJZFBlcXwAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAxNi0xMS0xOFQxNTozMjo0NyswMDowMBJiPnAAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMTYtMTEtMThUMTU6MzI6NDcrMDA6MDBjP4bMAAAARnRFWHRzb2Z0d2FyZQBJbWFnZU1hZ2ljayA2LjcuOC05IDIwMTQtMDUtMTIgUTE2IGh0dHA6Ly93d3cuaW1hZ2VtYWdpY2sub3Jn3IbtAAAAABh0RVh0VGh1bWI6OkRvY3VtZW50OjpQYWdlcwAxp/+7LwAAABh0RVh0VGh1bWI6OkltYWdlOjpoZWlnaHQAMTkyDwByhQAAABd0RVh0VGh1bWI6OkltYWdlOjpXaWR0aAAxOTLTrCEIAAAAGXRFWHRUaHVtYjo6TWltZXR5cGUAaW1hZ2UvcG5nP7JWTgAAABd0RVh0VGh1bWI6Ok1UaW1lADE0Nzk0ODMxNjfDDOUEAAAAD3RFWHRUaHVtYjo6U2l6ZQAwQkKUoj7sAAAAVnRFWHRUaHVtYjo6VVJJAGZpbGU6Ly8vbW50bG9nL2Zhdmljb25zLzIwMTYtMTEtMTgvOTJiZjNlMDg0MGFkZWJjNjRlMjZhMzgzODFmM2RkMmMuaWNvLnBuZ7VafDgAAAAASUVORK5CYII="/><meta data-react-helmet="true" name="description" content="Ngoc Nguyen is a Singapore-based Software Developer. Currently employed @ 2359Media"/><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/><meta data-react-helmet="true" name="apple-mobile-web-app-status-bar-style" content="black"/><meta data-react-helmet="true" name="msapplication-navbutton-color" content="#000"/><meta data-react-helmet="true" name="msapplication-TileColor" content="#000"/><meta data-react-helmet="true" name="theme-color" content="#000"/><meta data-react-helmet="true" name="google-site-verification" content="UlnCqEaT-_IXvcf5Y5levG2YHwz2v0cksM9XxTDMh7E"/><meta data-react-helmet="true" property="og:title" content="Ngoc Nguyen&#x27;s Personal Blog"/><meta data-react-helmet="true" property="og:image" content="/static/share-a0a529ffe5f685e1aa35b5ca4e2a32b2.png"/><meta data-react-helmet="true" property="og:image:width" content="880px"/><meta data-react-helmet="true" property="og:image:height" content="440px"/><meta data-react-helmet="true" property="og:image:alt" content="Ngoc Nguyen is a Singapore-based Software Developer. Currently employed @ 2359Media"/><meta data-react-helmet="true" name="twitter:title" content="Ngoc Nguyen&#x27;s Personal Blog"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:image" content="/static/share-a0a529ffe5f685e1aa35b5ca4e2a32b2.png"/><meta data-react-helmet="true" name="twitter:site" content="@luungoc2005"/><meta data-react-helmet="true" name="twitter:creator" content="@luungoc2005"/><meta data-react-helmet="true" name="twitter:description" content="Ngoc Nguyen is a Singapore-based Software Developer. Currently employed @ 2359Media"/><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-b3b573358bfc66d89e1e95dbf8319c09.css"/><link rel="icon" href="/favicon-32x32.png?v=40bc9fb58e1b78624390d3af3864c648" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#663399"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=40bc9fb58e1b78624390d3af3864c648"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=40bc9fb58e1b78624390d3af3864c648"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=40bc9fb58e1b78624390d3af3864c648"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=40bc9fb58e1b78624390d3af3864c648"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=40bc9fb58e1b78624390d3af3864c648"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=40bc9fb58e1b78624390d3af3864c648"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=40bc9fb58e1b78624390d3af3864c648"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=40bc9fb58e1b78624390d3af3864c648"/><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><link as="script" rel="preload" href="/webpack-runtime-0a1eb7dabad1bb6a94eb.js"/><link as="script" rel="preload" href="/framework-efec0dbc576af5a2b0da.js"/><link as="script" rel="preload" href="/app-82af785a5992b4f336ae.js"/><link as="script" rel="preload" href="/component---src-components-blog-post-blog-post-tsx-77f2c2e37c3add5737aa.js"/><link as="fetch" rel="preload" href="/page-data/blog/2020-06-11-brief-history-of-nlp-p3/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="AppLayout-module--layout--jfjNv"><header class="Header-module--header--Wcvsx" id="page-title"><div class="Header-module--header__container--FQQsy"><div class="Header-module--header__content--Lz0RY"><a class="Header-module--header__logo--O4AxC" href="/"><h1>Ngoc Nguyen</h1><span>~ programming and stuffs</span></a><div class="Header-module--header__navigation--IcX3m"><a class="HeaderLink-module--link--2ew99" href="/blog">blog</a><a class="HeaderLink-module--link--2ew99" href="/about">about</a><a class="HeaderLink-module--link--2ew99" target="_blank" rel="noopener noreferrer" href="https://github.com/luungoc2005"><svg height="17" viewBox="0 0 18 17" width="18" class="HeaderLink-module--link__icon--cUb1K"><title>Github</title><path d="m195.711029 1c-4.810968 0-8.711029 3.90006063-8.711029 8.71102924 0 3.85027496 2.500065 7.11691086 5.958344 8.27547776.435551.0696883.574928-.2003537.574928-.4355514 0-.2003537 0-.7491486 0-1.472164-2.412955.5226618-2.926906-1.1672779-2.926906-1.1672779-.400707-1.0104794-.966924-1.2805213-.966924-1.2805213-.792704-.5400838.060977-.5226618.060977-.5226618.871103.0609772 1.332788.8972361 1.332788.8972361.757859 1.3240764 2.03838.9320801 2.534909.7230154.078399-.5662169.304886-.9495022.548795-1.1672779-1.933849-.2177758-3.963518-.9669243-3.963518-4.28582642 0-.96692425.331019-1.74220585.897236-2.36068893-.087111-.21777573-.391997-1.12372277.08711-2.29971172 0 0 .731726-.23519779 2.395533.88852499.688171-.19164265 1.43732-.28746397 2.177757-.28746397.740438 0 1.489586.09582132 2.177758.28746397 1.663806-1.12372278 2.395533-.88852499 2.395533-.88852499.479106 1.17598895.17422 2.08193599.08711 2.29971172.566217.61848308.897236 1.39376468.897236 2.36068893 0 3.32761312-2.038381 4.05933962-3.98094 4.27711532.313597.2700419.601061.8014147.601061 1.6115404v2.3868221c0 .2351977.139376.5139507.583639.4355514 3.458278-1.1672779 5.949632-4.4252028 5.949632-8.27547776 0-2.3103086-.917766-4.52599297-2.551401-6.15962785-1.633635-1.63363487-3.849319-2.55140139-6.159628-2.55140139z" fill="#9ea0a6" transform="translate(-187 -1)"></path></svg>github</a></div></div></div></header><div class="PostsLayout-module--layout--eGkUk"><div class="container-fluid row" style="margin-left:auto;margin-right:auto"><aside class="col-xs-12 col-sm-3 PostsLayout-module--side_bar--eH3NI"><div class="row AboutColumn-module--about_col--vGngi"><div class="col-xs-2 col-sm-12 AboutColumn-module--about_col__avatar--FfREI"><img alt="Avatar" src="/static/avatar-f36c5e697b48172fbeb4392a7e2b7e03.png"/></div><div class="col-xs-8 col-sm-12 AboutColumn-module--about_col__desc_container--pczVC"><div class="AboutColumn-module--about_col__heading--6ULIu">Ngoc Nguyen</div><div class="AboutColumn-module--about_col__description--1IZO+">Software Developer, AI Enthusiast, Coffee Addict, plays Piano</div></div><div class="AboutColumn-module--about_col__details--WsCUp"><ul><li><span class="AboutColumn-module--about_col__details__icon--yKg4U"><svg class="svg-inline--fa fa-map-marker-alt fa-w-12 fa-fw" width="18" height="18" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="map-marker-alt" role="img" viewBox="0 0 384 512" data-fa-i2svg=""><title>Location</title><path fill="currentColor" d="M172.268 501.67C26.97 291.031 0 269.413 0 192 0 85.961 85.961 0 192 0s192 85.961 192 192c0 77.413-26.97 99.031-172.268 309.67-9.535 13.774-29.93 13.773-39.464 0zM192 272c44.183 0 80-35.817 80-80s-35.817-80-80-80-80 35.817-80 80 35.817 80 80 80z"></path></svg></span><span class="AboutColumn-module--about_col__details__text--vP5Cr">Singapore</span></li><li><a alt="Twitter" href="https://twitter.com/luungoc2005" target="_blank" rel="noopener noreferrer"><span class="AboutColumn-module--about_col__details__icon--yKg4U"><svg width="20px" height="15px" viewBox="0 0 20 15" version="1.1"><title>Twitter</title><defs></defs><g id="Good-One" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Footer_06" transform="translate(-1091.000000, -3948.000000)" fill="#9EA0A6"><g id="Group-7" transform="translate(0.000000, 3204.000000)"><g id="Group-6" transform="translate(75.000000, 733.000000)"><g id="dribbble" transform="translate(976.000000, 9.000000)"><path d="M53.2813915,2 C51.0959361,2 49.3247358,3.69382235 49.3247358,5.78774534 C49.3247358,6.08310267 49.3596502,6.37374182 49.4275918,6.64928284 C46.1380851,6.48980876 43.2222572,4.98471314 41.2708228,2.68885254 C40.9301711,3.25031454 40.7357826,3.90142174 40.7357826,4.59593608 C40.7357826,5.91041772 41.4331278,7.07014343 42.4956593,7.74672874 C41.8464394,7.72974333 41.236852,7.55800201 40.7027554,7.27396829 C40.7027554,7.29001007 40.7027554,7.30605184 40.7027554,7.32303724 C40.7027554,9.157461 42.066306,10.6880347 43.8771389,11.0362355 C43.5449799,11.1221062 43.1958354,11.1692879 42.8344238,11.1692879 C42.5796427,11.1692879 42.331467,11.1447534 42.0898968,11.1032335 C42.5937972,12.603611 44.0554857,13.7038878 45.7870533,13.7331404 C44.4319955,14.7447157 42.7259059,15.3552466 40.8726095,15.3552466 C40.5527177,15.3552466 40.237544,15.3344867 39.9280322,15.3014595 C41.6794162,16.3753145 43.7591847,17 45.9937091,17 C53.2719552,17 57.2522018,11.2287368 57.2522018,6.22464771 C57.2522018,6.06328636 57.2484273,5.89720684 57.2408782,5.73490186 C58.0146578,5.20080523 58.6855813,4.53648717 59.2159034,3.7768621 C58.5062909,4.07505033 57.7438349,4.27887519 56.9436336,4.37135128 C57.7598767,3.90142174 58.3873931,3.16066935 58.6827504,2.27648465 C57.9184071,2.70961248 57.0710242,3.02478611 56.1707977,3.19369653 C55.4479743,2.45954957 54.4203573,2 53.2813915,2" id="Fill-1"></path></g></g></g></g></g></svg></span><span class="AboutColumn-module--about_col__details__text--vP5Cr">Twitter</span></a></li><li><a alt="Github" href="https://github.com/luungoc2005" target="_blank" rel="noopener noreferrer"><span class="AboutColumn-module--about_col__details__icon--yKg4U"><svg height="17" viewBox="0 0 18 17" width="18"><title>Github</title><path d="m195.711029 1c-4.810968 0-8.711029 3.90006063-8.711029 8.71102924 0 3.85027496 2.500065 7.11691086 5.958344 8.27547776.435551.0696883.574928-.2003537.574928-.4355514 0-.2003537 0-.7491486 0-1.472164-2.412955.5226618-2.926906-1.1672779-2.926906-1.1672779-.400707-1.0104794-.966924-1.2805213-.966924-1.2805213-.792704-.5400838.060977-.5226618.060977-.5226618.871103.0609772 1.332788.8972361 1.332788.8972361.757859 1.3240764 2.03838.9320801 2.534909.7230154.078399-.5662169.304886-.9495022.548795-1.1672779-1.933849-.2177758-3.963518-.9669243-3.963518-4.28582642 0-.96692425.331019-1.74220585.897236-2.36068893-.087111-.21777573-.391997-1.12372277.08711-2.29971172 0 0 .731726-.23519779 2.395533.88852499.688171-.19164265 1.43732-.28746397 2.177757-.28746397.740438 0 1.489586.09582132 2.177758.28746397 1.663806-1.12372278 2.395533-.88852499 2.395533-.88852499.479106 1.17598895.17422 2.08193599.08711 2.29971172.566217.61848308.897236 1.39376468.897236 2.36068893 0 3.32761312-2.038381 4.05933962-3.98094 4.27711532.313597.2700419.601061.8014147.601061 1.6115404v2.3868221c0 .2351977.139376.5139507.583639.4355514 3.458278-1.1672779 5.949632-4.4252028 5.949632-8.27547776 0-2.3103086-.917766-4.52599297-2.551401-6.15962785-1.633635-1.63363487-3.849319-2.55140139-6.159628-2.55140139z" fill="#9ea0a6" transform="translate(-187 -1)"></path></svg></span><span class="AboutColumn-module--about_col__details__text--vP5Cr">Github</span></a></li><li><a alt="Facebook" href="https://www.facebook.com/luungoc2005" target="_blank" rel="noopener noreferrer"><span class="AboutColumn-module--about_col__details__icon--yKg4U"><svg width="9px" height="18px" viewBox="0 0 9 18" version="1.1"><title>Facebook</title><defs></defs><g id="Good-One" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Footer_06" transform="translate(-1051.000000, -3946.000000)" fill="#9EA0A6" fill-rule="nonzero"><g id="Group-7" transform="translate(0.000000, 3204.000000)"><g id="Group-6" transform="translate(75.000000, 733.000000)"><g id="dribbble" transform="translate(976.000000, 9.000000)"><path d="M9,0 L9,3.6 L7.2,3.6 C6.579,3.6 6.3,4.329 6.3,4.95 L6.3,7.2 L9,7.2 L9,10.8 L6.3,10.8 L6.3,18 L2.7,18 L2.7,10.8 L0,10.8 L0,7.2 L2.7,7.2 L2.7,3.6 C2.7,1.6117749 4.3117749,3.99680289e-16 6.3,0 L9,0 Z" id="Shape"></path></g></g></g></g></g></svg></span><span class="AboutColumn-module--about_col__details__text--vP5Cr">Facebook</span></a></li><li><a alt="LinkedIn" href="https://www.linkedin.com/in/luungoc2005/" target="_blank" rel="noopener noreferrer"><span class="AboutColumn-module--about_col__details__icon--yKg4U"><svg width="18" height="18" viewBox="0 0 18 18"><title>
    LinkedIn
  </title><path fill="#9EA0A6" fill-rule="nonzero" d="M18 18h-4v-6.75c0-1.06-1.19-1.94-2.25-1.94S10 10.19 10 11.25V18H6V6h4v2c.66-1.07 2.36-1.76 3.5-1.76 2.5 0 4.5 2.04 4.5 4.51V18zM4 18H0V6h4v12zM2 0a2 2 0 1 1 0 4 2 2 0 0 1 0-4z"></path></svg></span><span class="AboutColumn-module--about_col__details__text--vP5Cr">LinkedIn</span></a></li></ul></div></div></aside><section class="col-xs-12 col-sm-9 PostsLayout-module--posts_content---0yRu"><header><div class="PageHeader-module--page_header---OFxr"><p class="PageHeader-module--page_header__text--W8IV-">A history of progress on text representation in NLP (Part 3 - Transformer models)</p></div></header><section class="BlogPost-module--post_meta--vvhwE"><span><svg class="svg-inline--fa fa-calendar-alt fa-w-14 fa-fw" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="calendar-alt" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M0 464c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48V192H0v272zm320-196c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12h-40c-6.6 0-12-5.4-12-12v-40zm0 128c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12h-40c-6.6 0-12-5.4-12-12v-40zM192 268c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12h-40c-6.6 0-12-5.4-12-12v-40zm0 128c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12h-40c-6.6 0-12-5.4-12-12v-40zM64 268c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12H76c-6.6 0-12-5.4-12-12v-40zm0 128c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12H76c-6.6 0-12-5.4-12-12v-40zM400 64h-48V16c0-8.8-7.2-16-16-16h-32c-8.8 0-16 7.2-16 16v48H160V16c0-8.8-7.2-16-16-16h-32c-8.8 0-16 7.2-16 16v48H48C21.5 64 0 85.5 0 112v48h448v-48c0-26.5-21.5-48-48-48z"></path></svg>Jun 11<!-- --> · <!-- -->9 min read</span></section><article class="BlogPost-module--post_content--iLhZI"><h1>Introduction</h1>
<hr>
<div class="custom-block snippet"><div class="custom-block-body"><p>This part is, in fact, a continuation of the previous part - still about sentence-level representations. However, I will discuss on what has been the state-of-the-art architecture for the last few years - Transformers.</p></div></div>
<p>Transformers are a class of sequential models based on the attention mechanism. In practice, they would stand in place of the LSTM layers that was the point of focus in <a href="/2020-06-06-brief-history-of-nlp-p2">part 2</a>.</p>
<h1>Transformer models</h1>
<hr>
<h1>1. Attention Is All You Need</h1>
<p>Prior to this, <em>attention mechanism</em> has been a major breakthrough for machine translation (which are still RNN-based). One of the more prominent papers on Attention mechanism for machine translation would be <a href="https://arxiv.org/pdf/1508.04025">Effective Approaches to Attention-based Neural Machine Translation</a>. As such, there were also various attempts to apply attention mechanism to RNN networks to various degrees of success, such as <a href="https://arxiv.org/pdf/1506.01057v2.pdf">A Hierarchical Neural Autoencoder for Paragraphs and Documents</a>.</p>
<p>However, <em>Attention is all you need</em> is the paper that first introduces the <em>Transformer</em> architecture - this was considered the most exciting breakthrough for NLP since ages. As its name would indicate, it relies on Attention mechanism at its core, but the application is vastly different from prior literature. To avoid repeating, I would suggest reading <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a>, an excellent explanation on how Transformers work. In summary, Transformers are theoretically more computationally efficient, and does not suffer from gradient vanishing - which was RNN networks' Achilles heel. It can almost be used as a drop-in replacement for RNN networks, and would bring comparable-to-greater results.</p>
<p>References:</p>
<ul>
<li><a href="https://arxiv.org/pdf/1508.04025">Effective Approaches to Attention-based Neural Machine Translation</a></li>
<li><a href="https://arxiv.org/pdf/1506.01057v2.pdf">A Hierarchical Neural Autoencoder for Paragraphs and Documents</a></li>
<li><a href="https://arxiv.org/pdf/1706.03762">Attention Is All You Need</a></li>
<li><a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></li>
</ul>
<h1>2. GPT</h1>
<p>GPT (or GPT-1) by OpenAI was as straightforward as it gets. It directly applies the new Transformer architecture to a language modeling (predicting the next word) problem. One thing it brought to the table was the standard procedure on applying the Transformer to downstream tasks, which bears some differences when compared to LSTM models (e.g for question answering and textual entailment, you would concatenate the 2 sentences, separated by a special token, instead of running the 2 sentences through the single encoder separately). Nevertheless, it quickly became state-of-the-art and dethrones ULMFiT, signaling Transformers becoming the new norm. It also raised the bars on <em>compute requirement</em>, for that matter, as ULMFiT at the time still had the benefit of being massively faster to train.</p>
<p><em>Side note:</em> Although OpenAI has since released GPT-2 and GPT-3, where GPT-2 actually is very prominent model and has a lot of applications, I won't mention them here because they no longer focus on the purpose of textual representation, but only emphasizes on text <em>generation</em> instead. Meanwhile, GPT-3 is... in short, a massively scaled up version of GPT-2, that cannot be run on consumer hardware.</p>
<p>References:</p>
<ul>
<li><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language
Understanding with
Unsupervised Learning</a></li>
</ul>
<h1>3. BERT</h1>
<p>With GPT being state of the art, it still had one major weakness that resembles RNN networks: its language modeling training objective gives it the unidirectional information handicap. Basically, every timestep would only be able to take the information from the words before it - done through attention masking. BERT introduced a new objective that makes it bi-directional, which actually resembles a <em>denoising autoencoder</em>: The task is essentially recovering damaged information from a given input sentence. The input sentence would have its words masked out (like a cloze test), and some of its words swapped out randomly. This looks a bit like this:</p>
<table>
<thead>
<tr>
<th align="center">Input</th>
<th align="center">Target</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code class="language-text">The [MASK] brown fox jump</code></td>
<td align="center"><code class="language-text">- quick - - - jumps</code></td>
</tr>
</tbody>
</table>
<p>Note that the target does not need to recover exactly the input sentence, as the model would just learn to copy from the input - which would be redundant.</p>
<p>As can be seen - this training objective would help the model learn grammatical structures and syntax in a manner that can be said to be a generalization of Word2Vec skip-gram or CBOW methods: by collocations of words.</p>
<p>BERT - at the time of release - still uses sub-word segmentation, which means this masking sometimes result in word segments being masked out - making it easy to recover. This was later addressed by the authors with an update called "whole word masking". There was also <em>Span BERT</em> which takes it to another level by masking out 3 consecutive words, which can lead to improved performance on span-related task, specifically question answering (predicting the span of the answer in the input paragraph).</p>
<p>In addition to this, the authors also introduced a next sentence prediction task to prime the model for multi-sequence tasks such as question answering and textual entailment. After the initial training, the 2nd finetuning task is to have a sequence of 2 sentences. These 2 sentences can either be taken directly from the dataset to be 2 continuous sentences, or the 2nd sentence can be randomized. The task to classify whether the 2nd sentence is randomized or taken from the same context heavily resembles a textual entailment task, only this does not require a labelled dataset, hence the entire procedure remains unsupervised (or semi-supervised to be more accurate).</p>
<table>
<thead>
<tr>
<th align="center">First Sentence</th>
<th align="center">Second Sentence</th>
<th align="center">Target</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code class="language-text">I&#39;ve built up my savings.</code></td>
<td align="center"><code class="language-text">I can now travel the world with it</code></td>
<td align="center"><code class="language-text">True</code></td>
</tr>
<tr>
<td align="center"><code class="language-text">I&#39;ve built up my savings.</code></td>
<td align="center"><code class="language-text">I like tacos.</code></td>
<td align="center"><code class="language-text">False</code></td>
</tr>
</tbody>
</table>
<p>Hold on to the next sentence prediction task, however, as RoBERTa, a model later released by Facebook, proved that the task can actually hurt performance. RoBERTa merely made slight alterations to the training parameters to optimize BERT, and actually resulted in better performance than even XLNet - which uses permutation language modeling to supposedly remedies the limitations from BERT's training task. Most importantly, RoBERTa proved BERT's easier-to-understand and implement task was adequate for reaching state-of-the-art results, and XLNet - which would theoretically be an improvement - actually could not improve upon BERT's training task emperically.</p>
<p>This next sentence prediction task was later ammended by ALBERT, which, in short is BERT but with weight tying and embedding factorization (this in itself can be implemented by a ~10-line code change in BERT). The authors replaced the next sentence prediction task with a sentence <em>order</em> prediction task and demonstrated this can improve performance on downstream tasks. This is how it looks like:</p>
<table>
<thead>
<tr>
<th align="center">First Sentence</th>
<th align="center">Second Sentence</th>
<th align="center">Target</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code class="language-text">I&#39;ve built up my savings.</code></td>
<td align="center"><code class="language-text">I can now travel the world with it</code></td>
<td align="center"><code class="language-text">True</code></td>
</tr>
<tr>
<td align="center"><code class="language-text">I can now travel the world with it</code></td>
<td align="center"><code class="language-text">I&#39;ve built up my savings.</code></td>
<td align="center"><code class="language-text">False</code></td>
</tr>
</tbody>
</table>
<p>The bigger contribution of ALBERT, however, was that - thanks to the memory savings from weight-tying and embedding factorization, that despite this still hurting downstream performance, it facilitated running <em>even bigger</em> models, which ultimately brings additional performance. ALBERT became the state-of-the-art model that can be run on consumer GPU, to the time of writing this blog.</p>
<p>On BERT itself, because of its heavy computational requirements that makes it unsound for production settings, quickly gave rise to distillation techniques - in which a smaller Transformer model (the student) would learn to replicate the bigger model (the teacher)'s results. Thanks to these efforts, the distilled variants of BERT can be used in production and is in fact rolled out on both Google and Bing. There's also efforts on hastening BERT training, namely LAMB optimizer to train BERT on larger batch sizes, and ELECTRA - a highly recommended read for its interesting idea, albeit with limited application.</p>
<p>BERT also gave rise to <em>Bertology</em>, due to its attention mechanism making it easy to visualize inspect what the model <em>learns</em>. Turns out, BERT is heavily overparameterized, which theoretically means BERT can be more optimized, and that there are a lot of attention patterns in BERT that are not optimized. There are attempts on using this knowledge to optimize BERT, whether it be training time or improve downstream performance, but so far there has not been any breakthroughs on the front.</p>
<p>References</p>
<ul>
<li><a href="https://arxiv.org/pdf/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li>
<li><a href="https://arxiv.org/pdf/1907.10529">SpanBERT: Improving Pre-training by Representing and Predicting Spans</a></li>
<li><a href="https://arxiv.org/pdf/1906.08237">XLNet: Generalized Autoregressive Pretraining for Language Understanding</a></li>
<li><a href="https://arxiv.org/pdf/1907.11692">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></li>
<li><a href="https://arxiv.org/pdf/1909.11942">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a></li>
<li><a href="https://arxiv.org/pdf/2003.10555">ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</a></li>
</ul>
<h1>Looking forward</h1>
<hr>
<h2>On Transformers</h2>
<p>Transformers themselves are not the silver bullet: there are a lot of remaining issues with them, with teams racing to address each issues, but so far without any major breakthroughs:</p>
<p>Transformers are hard to train: training transformers are usually more unstable than training RNN networks. For RNNs you usually can just use the default <code class="language-text">Adam(lr=1e-3)</code> - or the range of useable learning rates and batch sizes are actually very flexible - and it would converge to reasonable performance. Not so for Transformers - which usually require a <em>learning rate schedule</em>, which is often a linear warmup. Attempts to tackle this include new optimizers, most prominently the Adam-based RAdam and LAMB (which is optimized for training on huge batch sizes).</p>
<p>Transformers are slow and has a hard cap on sequence length - while RNNs are theoretically limitless (if you don't count in gradient vanishing which in the end still makes Transformers superior). The biggest problem with Transformers so far is that the self-attention mechanism is <em>O(n<sup>2</sup>)</em> time and space where n is the sequence length. The following papers are some of the most prominent in trying to tackle these issues, often by using sparsity or approximations of the self-attention, but yet to a satisfactory degree of success:</p>
<ul>
<li><a href="https://arxiv.org/pdf/1901.02860">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</a></li>
<li><a href="https://arxiv.org/pdf/1905.07799">Adaptive Attention Span in Transformers</a></li>
<li><a href="https://openreview.net/pdf?id=SylKikSYDH">Compressive Transformers for Long-Range Sequence Modelling</a></li>
<li><a href="https://arxiv.org/pdf/2001.04451">Reformer: The Efficient Transformer</a></li>
<li><a href="https://arxiv.org/pdf/2006.04768">Linformer: Self-Attention with Linear Complexity</a></li>
</ul>
<h2>On RNNs</h2>
<p>There are still ongoing efforts on improving RNNs, mostly closing the gap between LSTM and Transformers performance. These still have not managed to make LSTM networks catch up to Transformers, but some can massively improve LSTM networks - which are still being used extensively outside of the NLP world, most prominently for Reinforcement Learning.</p>
<ul>
<li><a href="https://arxiv.org/pdf/1810.09536">Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks</a></li>
<li><a href="https://arxiv.org/pdf/1607.06450.pdf">Layer Normalization</a> - <em>(also a very important building block for Transformers)</em></li>
<li><a href="https://arxiv.org/pdf/1909.01792">Mogrifier LSTM</a></li>
</ul></article><section><div shortname="luungoc2005" config="[object Object]" id="disqus_thread"></div></section></section></div></div><div class="Footer-module--footer--iTLBh"><section class="Container-module--container--37L5Z"><div class="Footer-module--footer__content--ZBH5p"><a href="https://luungoc2005.github.io" target="_blank" rel="noopener noreferrer"></a><ul class="Footer-module--footer__list--EQmCA"><li class="Footer-module--footer__item--cL2qa"><a alt="Twitter" href="https://twitter.com/luungoc2005" target="_blank" rel="noopener noreferrer"><svg width="20px" height="15px" viewBox="0 0 20 15" version="1.1"><title>Twitter</title><defs></defs><g id="Good-One" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Footer_06" transform="translate(-1091.000000, -3948.000000)" fill="#9EA0A6"><g id="Group-7" transform="translate(0.000000, 3204.000000)"><g id="Group-6" transform="translate(75.000000, 733.000000)"><g id="dribbble" transform="translate(976.000000, 9.000000)"><path d="M53.2813915,2 C51.0959361,2 49.3247358,3.69382235 49.3247358,5.78774534 C49.3247358,6.08310267 49.3596502,6.37374182 49.4275918,6.64928284 C46.1380851,6.48980876 43.2222572,4.98471314 41.2708228,2.68885254 C40.9301711,3.25031454 40.7357826,3.90142174 40.7357826,4.59593608 C40.7357826,5.91041772 41.4331278,7.07014343 42.4956593,7.74672874 C41.8464394,7.72974333 41.236852,7.55800201 40.7027554,7.27396829 C40.7027554,7.29001007 40.7027554,7.30605184 40.7027554,7.32303724 C40.7027554,9.157461 42.066306,10.6880347 43.8771389,11.0362355 C43.5449799,11.1221062 43.1958354,11.1692879 42.8344238,11.1692879 C42.5796427,11.1692879 42.331467,11.1447534 42.0898968,11.1032335 C42.5937972,12.603611 44.0554857,13.7038878 45.7870533,13.7331404 C44.4319955,14.7447157 42.7259059,15.3552466 40.8726095,15.3552466 C40.5527177,15.3552466 40.237544,15.3344867 39.9280322,15.3014595 C41.6794162,16.3753145 43.7591847,17 45.9937091,17 C53.2719552,17 57.2522018,11.2287368 57.2522018,6.22464771 C57.2522018,6.06328636 57.2484273,5.89720684 57.2408782,5.73490186 C58.0146578,5.20080523 58.6855813,4.53648717 59.2159034,3.7768621 C58.5062909,4.07505033 57.7438349,4.27887519 56.9436336,4.37135128 C57.7598767,3.90142174 58.3873931,3.16066935 58.6827504,2.27648465 C57.9184071,2.70961248 57.0710242,3.02478611 56.1707977,3.19369653 C55.4479743,2.45954957 54.4203573,2 53.2813915,2" id="Fill-1"></path></g></g></g></g></g></svg></a></li><li class="Footer-module--footer__item--cL2qa"><a alt="Github" href="https://github.com/luungoc2005" target="_blank" rel="noopener noreferrer"><svg height="17" viewBox="0 0 18 17" width="18"><title>Github</title><path d="m195.711029 1c-4.810968 0-8.711029 3.90006063-8.711029 8.71102924 0 3.85027496 2.500065 7.11691086 5.958344 8.27547776.435551.0696883.574928-.2003537.574928-.4355514 0-.2003537 0-.7491486 0-1.472164-2.412955.5226618-2.926906-1.1672779-2.926906-1.1672779-.400707-1.0104794-.966924-1.2805213-.966924-1.2805213-.792704-.5400838.060977-.5226618.060977-.5226618.871103.0609772 1.332788.8972361 1.332788.8972361.757859 1.3240764 2.03838.9320801 2.534909.7230154.078399-.5662169.304886-.9495022.548795-1.1672779-1.933849-.2177758-3.963518-.9669243-3.963518-4.28582642 0-.96692425.331019-1.74220585.897236-2.36068893-.087111-.21777573-.391997-1.12372277.08711-2.29971172 0 0 .731726-.23519779 2.395533.88852499.688171-.19164265 1.43732-.28746397 2.177757-.28746397.740438 0 1.489586.09582132 2.177758.28746397 1.663806-1.12372278 2.395533-.88852499 2.395533-.88852499.479106 1.17598895.17422 2.08193599.08711 2.29971172.566217.61848308.897236 1.39376468.897236 2.36068893 0 3.32761312-2.038381 4.05933962-3.98094 4.27711532.313597.2700419.601061.8014147.601061 1.6115404v2.3868221c0 .2351977.139376.5139507.583639.4355514 3.458278-1.1672779 5.949632-4.4252028 5.949632-8.27547776 0-2.3103086-.917766-4.52599297-2.551401-6.15962785-1.633635-1.63363487-3.849319-2.55140139-6.159628-2.55140139z" fill="#9ea0a6" transform="translate(-187 -1)"></path></svg></a></li><li class="Footer-module--footer__item--cL2qa"><a alt="Facebook" href="https://www.facebook.com/luungoc2005" target="_blank" rel="noopener noreferrer"><svg width="9px" height="18px" viewBox="0 0 9 18" version="1.1"><title>Facebook</title><defs></defs><g id="Good-One" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Footer_06" transform="translate(-1051.000000, -3946.000000)" fill="#9EA0A6" fill-rule="nonzero"><g id="Group-7" transform="translate(0.000000, 3204.000000)"><g id="Group-6" transform="translate(75.000000, 733.000000)"><g id="dribbble" transform="translate(976.000000, 9.000000)"><path d="M9,0 L9,3.6 L7.2,3.6 C6.579,3.6 6.3,4.329 6.3,4.95 L6.3,7.2 L9,7.2 L9,10.8 L6.3,10.8 L6.3,18 L2.7,18 L2.7,10.8 L0,10.8 L0,7.2 L2.7,7.2 L2.7,3.6 C2.7,1.6117749 4.3117749,3.99680289e-16 6.3,0 L9,0 Z" id="Shape"></path></g></g></g></g></g></svg></a></li><li class="Footer-module--footer__item--cL2qa"><a alt="LinkedIn" href="https://www.linkedin.com/in/luungoc2005/" target="_blank" rel="noopener noreferrer"><svg width="18" height="18" viewBox="0 0 18 18"><title>
    LinkedIn
  </title><path fill="#9EA0A6" fill-rule="nonzero" d="M18 18h-4v-6.75c0-1.06-1.19-1.94-2.25-1.94S10 10.19 10 11.25V18H6V6h4v2c.66-1.07 2.36-1.76 3.5-1.76 2.5 0 4.5 2.04 4.5 4.51V18zM4 18H0V6h4v12zM2 0a2 2 0 1 1 0 4 2 2 0 0 1 0-4z"></path></svg></a></li></ul></div></section></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  
  if(!(parseInt(navigator.doNotTrack) === 1 || parseInt(window.doNotTrack) === 1 || parseInt(navigator.msDoNotTrack) === 1 || navigator.doNotTrack === "yes")) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-87659525-1', 'auto', {});
      
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/2020-06-11-brief-history-of-nlp-p3/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-d16eea1d5320b6f1999f.js"],"app":["/app-82af785a5992b4f336ae.js"],"component---src-components-blog-post-blog-post-tsx":["/component---src-components-blog-post-blog-post-tsx-77f2c2e37c3add5737aa.js"],"component---src-pages-404-tsx":["/component---src-pages-404-tsx-0e61ace1b6de18f298f7.js"],"component---src-pages-about-tsx":["/component---src-pages-about-tsx-3cc9389b3ac6cb62776b.js"],"component---src-pages-blog-tsx":["/component---src-pages-blog-tsx-21139191c2cef8864b6b.js"],"component---src-pages-index-tsx":["/component---src-pages-index-tsx-1bf71822739027f54e72.js"]};/*]]>*/</script><script src="/polyfill-d16eea1d5320b6f1999f.js" nomodule=""></script><script src="/component---src-components-blog-post-blog-post-tsx-77f2c2e37c3add5737aa.js" async=""></script><script src="/app-82af785a5992b4f336ae.js" async=""></script><script src="/framework-efec0dbc576af5a2b0da.js" async=""></script><script src="/webpack-runtime-0a1eb7dabad1bb6a94eb.js" async=""></script></body></html>